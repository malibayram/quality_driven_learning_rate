{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30158, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gs/crm1zcvj00j1kl0l1lvz4qf40000gn/T/ipykernel_1895/2008816879.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tr_embeddings.append(torch.load(f'tr_cosmos_embeddings_{i}.pt'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tr_embeddings = []\n",
    "\n",
    "for i in range(3):\n",
    "    tr_embeddings.append(torch.load(f'tr_cosmos_embeddings_{i}.pt'))\n",
    "\n",
    "tr_embeddings = torch.cat(tr_embeddings)\n",
    "\n",
    "print(tr_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alibayram/Desktop/quality_driven_learning_rate/codes/pre_processor.py:147: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'acil-tip' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df['doctor_speciality'].isin(speciality_mapping[key]), 'doctor_speciality'] = key\n",
      "/Users/alibayram/Desktop/quality_driven_learning_rate/codes/pre_processor.py:154: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'dr-ogr-uyesi' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df['doctor_title'].isin(title_mapping[key]), 'doctor_title'] = key\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctor_title</th>\n",
       "      <th>doctor_speciality</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Merhaba, Yaklaşık 4 aydır sağ omuzumda kolumu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Hocam merhaba 29 yaşında erkek hasta hareketle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Meraba hocam sorum şu , bir erkek bayıltılıp a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Merhaba doktor hanim ben 3 yildir evliyim. Hic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Merhaba.. Benim size sorum olacakti .. Ben 3 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124743</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Merhaba L3 4 L4 5 duzeyınde anular buldıng ızl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124744</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>hocam merhaba , son kontrolüme göre gebelik ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124745</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Hocam 15 yildir basur sikintisi çeken biriyim ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124746</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>hocam öncelikle meraba ortalama 3 yıl önce kad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124747</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Merhaba hocam testis kanseri olan hastalarda k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124748 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doctor_title doctor_speciality  \\\n",
       "0                 7                 0   \n",
       "1                 6                 0   \n",
       "2                 6                 0   \n",
       "3                 6                 1   \n",
       "4                 6                 1   \n",
       "...             ...               ...   \n",
       "124743            6                 0   \n",
       "124744            6                 1   \n",
       "124745            6                 0   \n",
       "124746            6                 1   \n",
       "124747            8                 0   \n",
       "\n",
       "                                                     text  \n",
       "0       Merhaba, Yaklaşık 4 aydır sağ omuzumda kolumu ...  \n",
       "1       Hocam merhaba 29 yaşında erkek hasta hareketle...  \n",
       "2       Meraba hocam sorum şu , bir erkek bayıltılıp a...  \n",
       "3       Merhaba doktor hanim ben 3 yildir evliyim. Hic...  \n",
       "4       Merhaba.. Benim size sorum olacakti .. Ben 3 s...  \n",
       "...                                                   ...  \n",
       "124743  Merhaba L3 4 L4 5 duzeyınde anular buldıng ızl...  \n",
       "124744  hocam merhaba , son kontrolüme göre gebelik ha...  \n",
       "124745  Hocam 15 yildir basur sikintisi çeken biriyim ...  \n",
       "124746  hocam öncelikle meraba ortalama 3 yıl önce kad...  \n",
       "124747  Merhaba hocam testis kanseri olan hastalarda k...  \n",
       "\n",
       "[124748 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from codes.pre_processor import PreProcessor\n",
    "\n",
    "df = pd.read_csv('new_df.csv')\n",
    "\n",
    "preprocessor = PreProcessor(df)\n",
    "df = preprocessor.preprocess()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tr_tokenizer = AutoTokenizer.from_pretrained(\"alibayram/tr_tokenizer\")\n",
    "tr_tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear cebir\n",
    "\n",
    "def embed_text(text):\n",
    "    # the average of the embeddings of the tokens\n",
    "    input_ids = tr_tokenizer(text)['input_ids']\n",
    "    embeddings = []\n",
    "    for i in input_ids:\n",
    "        embeddings.append(tr_embeddings[i])\n",
    "        \n",
    "    list_of_embeddings = torch.stack(embeddings)\n",
    "    # return means as list\n",
    "    return torch.mean(list_of_embeddings, axis=0).detach().numpy()\n",
    "\n",
    "embedded_text = embed_text(\"Merhaba, benim adım Ali. Bugün hava çok güzel.\")\n",
    "embedded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU fonksiyonu gelen değer 0'dan küçükse 0'a eşitler, diğer durumlarda değeri olduğu gibi bırakır.\n",
    "def ReLU(degerler):\n",
    "    degerler[degerler < 0] = 0\n",
    "    return degerler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tahmin_et(ornek, agirliklar, biaslar):\n",
    "    birinci_katman = np.matmul(ornek, agirliklar[0])\n",
    "    birinci_katman = birinci_katman + biaslar[0]\n",
    "    birinci_katman = ReLU(birinci_katman)\n",
    "    \n",
    "    ikinci_katman = np.matmul(birinci_katman, agirliklar[1])\n",
    "    \n",
    "    # Üçüncü katmanın çıktısını hesaplamak için softmax fonksiyonunu kullanıyoruz.\n",
    "    # Softmax fonksiyonu, çıktıları olasılık değerlerine dönüştürür. Şu şekilde çalışır:\n",
    "    # 1. İkinci katmandan gelen değerlerin exp() fonksiyonunu alır.\n",
    "    # 2. Bu değerleri toplar.\n",
    "    # 3. Her bir değeri toplam değere böler.\n",
    "    # Bu işlem sonucunda, her bir çıktı değeri 0 ile 1 arasında bir değer alır ve toplam değer 1 olur.\n",
    "    softmax_pay = np.exp(ikinci_katman)\n",
    "    softmax_payda = np.sum(softmax_pay, axis=1).reshape(-1,1)\n",
    "    softmax = softmax_pay / softmax_payda\n",
    "\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kayip_hesapla(y_tahmin, y_gercek):\n",
    "    '''\n",
    "    Kayıp fonksiyonu, modelin tahminlerinin ne kadar yanlış olduğunu ölçer.\n",
    "    Bu örnekte, çok sınıflı çapraz entropi kaybını kullanıyoruz.\n",
    "    Şu şekilde çalışır:\n",
    "    1. Her bir örneğin gerçek etiketinin one-hot encoding'ini alır.\n",
    "    2. Modelin tahminlerini logaritma alır.\n",
    "    3. Her bir örneğin kaybını hesaplar.\n",
    "    4. Tüm örneklerin kaybının ortalamasını alır.    \n",
    "    '''\n",
    "    global sinif_sayisi\n",
    "    sinif_sayisi = 2\n",
    "    ornek_sayisi = len(y_gercek)\n",
    "\n",
    "    # One-hot encoding\n",
    "    y_gercek_one_hot = (y_gercek[:, np.newaxis] == np.arange(sinif_sayisi))\n",
    "    # Şu şekilde bir matris oluşturur:\n",
    "    # [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    #  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    #  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    #  ...\n",
    "    #  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]\n",
    "\n",
    "    # Her bir örneğin kaybını hesaplar\n",
    "    kayip_ornek = (np.log(y_tahmin) * y_gercek_one_hot).sum(axis=1)\n",
    "    # Tüm örneklerin kaybının ortalamasını alır\n",
    "    return -np.mean(kayip_ornek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geri_yayilim(agirliklar, biaslar, girdi_verisi, etiketler, duzenleme_katsayisi = 1e-4):\n",
    "    '''\n",
    "    Adım 1: İleri geçiş (forward pass) yaparak modelin çıktısını hesaplama\n",
    "    Adım 2: Geri yayılım (backpropagation) ile ağırlık ve biasların türevlerini hesaplama\n",
    "    '''\n",
    "    numune_sayisi = girdi_verisi.shape[0]\n",
    "    \n",
    "    ### Adım 1: İleri Geçiş\n",
    "    # Katman 1: Giriş Katmanı -> Katman 2: Gizli Katman\n",
    "    gizli_katman_giris = np.matmul(girdi_verisi, agirliklar[0]) + biaslar[0]\n",
    "    # Gizli katman aktivasyonu (ReLU fonksiyonu)\n",
    "    gizli_katman_aktivasyonu = ReLU(gizli_katman_giris)\n",
    "    \n",
    "    # Katman 2: Gizli Katman -> Katman 3: Çıkış Katmanı\n",
    "    cikis_katman_giris = np.matmul(gizli_katman_aktivasyonu, agirliklar[1])\n",
    "    ekspotansiyel = np.exp(cikis_katman_giris)\n",
    "    toplam_ekspotansiyel = np.sum(ekspotansiyel, axis=1).reshape(-1, 1)\n",
    "    cikis_aktivasyonu = ekspotansiyel / toplam_ekspotansiyel\n",
    "    \n",
    "    ### Adım 2: Geri Yayılım\n",
    "    \n",
    "    # Katman 3: Çıkış Katmanı -> Katman 2: Gizli Katman için ağırlıkların türevini hesaplama\n",
    "    # delta2, kayıp fonksiyonunun cikis_katman_giris'e göre türevini temsil eder\n",
    "    etiketler_bir_sicak_vektor = (etiketler[:, np.newaxis] == np.arange(sinif_sayisi))\n",
    "    delta2 = (cikis_aktivasyonu - etiketler_bir_sicak_vektor)\n",
    "    gizli_katman_agirlik_turevi = np.matmul(gizli_katman_aktivasyonu.T, delta2)\n",
    "    \n",
    "    # Katman 2: Gizli Katman -> Katman 1: Giriş Katmanı için ağırlıkların türevini hesaplama\n",
    "    # delta1, gizli_katman_giris'in aktivasyon fonksiyonuna göre türevini temsil eder\n",
    "    delta1 = np.matmul(delta2, agirliklar[1].T) * (gizli_katman_giris > 0)\n",
    "    giris_katman_agirlik_turevi = np.matmul(girdi_verisi.T, delta1)\n",
    "    \n",
    "    # Ekstra katman türevi öğrenci projesi olabilir\n",
    "    \n",
    "    # Katman 1: Giriş Katmanı için türev yok (Giriş katmanı, sadece veriyi iletir)\n",
    "    \n",
    "    # Düzenleme katsayısı ile ağırlıkların türevini düzenleme\n",
    "    agirlik_turevleri = [giris_katman_agirlik_turevi / numune_sayisi + duzenleme_katsayisi * agirliklar[0], \n",
    "                         gizli_katman_agirlik_turevi / numune_sayisi + duzenleme_katsayisi * agirliklar[1]]\n",
    "    bias_turevleri = [np.mean(delta1, axis=0)]\n",
    "    \n",
    "    # agirlik_turevleri[0], agirliklar[0]'ın türevini ve agirlik_turevleri[1], agirliklar[1]'in türevini temsil eder; bias_turevleri için de benzer\n",
    "    return agirlik_turevleri, bias_turevleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(W, b, X, y, alpha = 1e-4):\n",
    "    '''\n",
    "    Step 1: explicit forward pass h(X;W,b)\n",
    "    Step 2: backpropagation for dW and db\n",
    "    '''\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    ### Step 1:\n",
    "    # layer 1 = input layer\n",
    "    # layer 1 (input layer) -> layer 2 (hidden layer)\n",
    "    z1 = np.matmul(X, W[0]) + b[0]\n",
    "    # layer 2 activation\n",
    "    a2 = ReLU(z1)\n",
    "    \n",
    "    # one more layer\n",
    "    \n",
    "    # layer 2 (hidden layer) -> layer 3 (output layer)\n",
    "    z2 = np.matmul(a2, W[1])\n",
    "    s = np.exp(z2)\n",
    "    total = np.sum(s, axis=1).reshape(-1,1)\n",
    "    sigma = s / total\n",
    "    \n",
    "    ### Step 2:\n",
    "    \n",
    "    # layer 2->layer 3 weights' derivative\n",
    "    # delta2 is \\partial L/partial z2, of shape (N,K)\n",
    "    y_one_hot_vec = (y[:,np.newaxis] == np.arange(sinif_sayisi))\n",
    "    delta2 = (sigma - y_one_hot_vec)\n",
    "    grad_W1 = np.matmul(a2.T, delta2)\n",
    "    \n",
    "    # layer 1->layer 2 weights' derivative\n",
    "    # delta1 is \\partial a2/partial z1\n",
    "    # layer 2 activation's (weak) derivative is 1*(z1>0)\n",
    "    delta1 = np.matmul(delta2, W[1].T)*(z1>0)\n",
    "    grad_W0 = np.matmul(X.T, delta1)\n",
    "    \n",
    "    # Possible student project: extra layer of derivative\n",
    "    \n",
    "    # no derivative for layer 1\n",
    "    \n",
    "    # the alpha part is the derivative for the regularization\n",
    "    # regularization = 0.5*alpha*(np.sum(W[1]**2) + np.sum(W[0]**2))\n",
    "    \n",
    "    \n",
    "    dW = [grad_W0 / N + alpha * W[0], grad_W1 / N + alpha * W[1]]\n",
    "    db = [np.mean(delta1, axis=0)]\n",
    "    # dW[0] is W[0]'s derivative, and dW[1] is W[1]'s derivative; similar for db\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (124748,), array([0, 0, 0, 1, 1], dtype=object))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_veri = df['doctor_speciality'].values\n",
    "type(y_veri), y_veri.shape, y_veri[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_veri_list = []\n",
    "X_veri_list.append(embed_text(\"Merhabalar, benim adım Ali. Bugün hava çok güzel.\"))\n",
    "\n",
    "X_veri = np.array(X_veri_list)\n",
    "X_veri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (124748, 768), (768,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map text to embeddings and convert to numpy\n",
    "X_veri_list = []\n",
    "for text in df['text']:\n",
    "    X_veri_list.append(embed_text(text))\n",
    "\n",
    "X_veri = np.array(X_veri_list)\n",
    "type(X_veri), X_veri.shape, X_veri[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123748, 768) (123748,)\n",
      "(1000, 768) (1000,)\n"
     ]
    }
   ],
   "source": [
    "X_test = X_veri[:1000]\n",
    "y_test = y_veri[:1000]\n",
    "\n",
    "X_egitim = X_veri[1000:]\n",
    "y_egitim = y_veri[1000:]\n",
    "\n",
    "print(X_egitim.shape, y_egitim.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_egitim[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametrelerin tanımlanması\n",
    "ogrenme_orani_eta = 5e-1  # Öğrenme oranı\n",
    "duzenleme_katsayisi_alpha = 1e-6  # Düzenleme katsayısı\n",
    "rmsprop_gamma = 0.99  # RMSprop için gamma değeri\n",
    "rmsprop_eps = 1e-3  # RMSprop için epsilon değeri\n",
    "toplam_iterasyon_sayisi = 100  # Gradyan iniş algoritmasının iterasyon sayısı\n",
    "gizli_katman_noron_sayisi = 256  # Gizli katmandaki nöron sayısı\n",
    "girdi_ozellik_sayisi = X_egitim.shape[1]  # Bir resimdeki piksel sayısı\n",
    "sinif_sayisi = 2  # Sınıf sayısı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0038652422,\n",
       " 0.012153784,\n",
       " 0.0016007624,\n",
       " 0.012870334,\n",
       " 0.012013456,\n",
       " 0.026700977,\n",
       " -0.01077178,\n",
       " -0.029163785,\n",
       " 0.014100477,\n",
       " -0.0076350453,\n",
       " 0.006495018,\n",
       " 0.0069767446,\n",
       " 0.014066488,\n",
       " -0.003869129,\n",
       " 0.014449706,\n",
       " 0.0021180848,\n",
       " 0.008775139,\n",
       " 0.00742837,\n",
       " 0.0021718235,\n",
       " -0.009240747,\n",
       " -0.025006,\n",
       " 0.0017618749,\n",
       " 0.0036908486,\n",
       " 8.8611916e-05,\n",
       " -0.015158061,\n",
       " -0.00618413,\n",
       " -0.010778325,\n",
       " 0.002779657,\n",
       " -0.008532285,\n",
       " 0.028836789,\n",
       " 0.011027516,\n",
       " -0.0009777647,\n",
       " 0.006853496,\n",
       " -0.0052956347,\n",
       " -0.00051327574,\n",
       " 0.0013211175,\n",
       " 0.015337447,\n",
       " 0.004009064,\n",
       " -0.0010593038,\n",
       " 0.010944274,\n",
       " -0.029160231,\n",
       " 0.034601517,\n",
       " 0.00547982,\n",
       " 0.0031273533,\n",
       " 0.006833258,\n",
       " -0.030714542,\n",
       " -0.0027795534,\n",
       " -0.013043098,\n",
       " 0.008413021,\n",
       " 0.00833334,\n",
       " 0.0002738147,\n",
       " 0.0007301546,\n",
       " -0.012476387,\n",
       " -0.03616415,\n",
       " -0.02337482,\n",
       " -0.021534009,\n",
       " -0.007463403,\n",
       " -0.009415559,\n",
       " -0.024384322,\n",
       " -0.01910168,\n",
       " 0.010278439,\n",
       " 0.015908571,\n",
       " 0.0013542258,\n",
       " -0.0114051225,\n",
       " -0.0009352055,\n",
       " 0.01403055,\n",
       " -0.0008700271,\n",
       " -0.019790815,\n",
       " 0.008376778,\n",
       " 0.02835124,\n",
       " 0.032819618,\n",
       " 0.01162855,\n",
       " -0.013602235,\n",
       " 0.016539332,\n",
       " 0.012477676,\n",
       " -0.021927355,\n",
       " -0.009181116,\n",
       " -0.01043313,\n",
       " -0.002959771,\n",
       " 0.017877312,\n",
       " 0.00923277,\n",
       " 0.008407343,\n",
       " 0.0137100555,\n",
       " 0.009631746,\n",
       " -0.011909449,\n",
       " 0.0005733488,\n",
       " 0.020987011,\n",
       " 0.0124931745,\n",
       " 0.008293118,\n",
       " -0.01230468,\n",
       " 0.004099827,\n",
       " -0.029101254,\n",
       " -0.017702796,\n",
       " 0.0015286179,\n",
       " -0.0074455803,\n",
       " -0.030550737,\n",
       " 0.011593081,\n",
       " -0.0069398712,\n",
       " -0.0019377936,\n",
       " 0.01977936,\n",
       " -0.012372286,\n",
       " 0.013517453,\n",
       " 0.012079037,\n",
       " -0.0006739245,\n",
       " -0.0067972946,\n",
       " -0.010672058,\n",
       " -0.033502813,\n",
       " 0.00016018483,\n",
       " -0.017648326,\n",
       " -0.00020651602,\n",
       " 0.0024714277,\n",
       " 0.020904798,\n",
       " -0.007962922,\n",
       " -0.010193018,\n",
       " 0.019598356,\n",
       " -0.013562138,\n",
       " 0.0004777666,\n",
       " 0.0022955583,\n",
       " -0.005795098,\n",
       " 0.0056393365,\n",
       " -0.0018052106,\n",
       " -0.015431875,\n",
       " -0.002634127,\n",
       " 0.004821897,\n",
       " 0.0077666645,\n",
       " 0.033817537,\n",
       " -0.01122959,\n",
       " 0.0023108067,\n",
       " 0.007194323,\n",
       " -0.0012272003,\n",
       " -0.031510543,\n",
       " 0.001564814,\n",
       " -0.0011430972,\n",
       " -0.04679727,\n",
       " -0.024433292,\n",
       " -0.015822805,\n",
       " 0.015897216,\n",
       " 0.0050417054,\n",
       " -0.0066656778,\n",
       " 0.0050549023,\n",
       " 0.019828226,\n",
       " 0.0030444125,\n",
       " 0.013288794,\n",
       " -0.01464361,\n",
       " 0.012338071,\n",
       " 0.0031377627,\n",
       " 0.0065606697,\n",
       " 0.031699736,\n",
       " 0.013402379,\n",
       " -0.014903999,\n",
       " -0.00060306315,\n",
       " 0.008376759,\n",
       " -0.022640707,\n",
       " 0.005192591,\n",
       " -0.025479956,\n",
       " 0.018299723,\n",
       " -0.019143812,\n",
       " -0.017052518,\n",
       " 0.0029543154,\n",
       " -0.009830793,\n",
       " 0.002240486,\n",
       " -0.0030355686,\n",
       " 0.008161409,\n",
       " -0.012069048,\n",
       " -0.0067489455,\n",
       " 0.001694972,\n",
       " -0.0069266497,\n",
       " 0.0071905074,\n",
       " 0.012873347,\n",
       " -0.0029582484,\n",
       " -0.006375829,\n",
       " 0.0060040215,\n",
       " 0.008185806,\n",
       " 0.026776338,\n",
       " 0.014891312,\n",
       " -0.025769025,\n",
       " -0.012652098,\n",
       " 0.011025192,\n",
       " -0.010957552,\n",
       " -0.007172696,\n",
       " -0.0036459868,\n",
       " 4.6902172e-05,\n",
       " 0.020976849,\n",
       " -0.0075936574,\n",
       " 0.010024218,\n",
       " 0.019012557,\n",
       " -0.00811854,\n",
       " -0.019073905,\n",
       " 0.01786268,\n",
       " 0.00737908,\n",
       " 0.028693758,\n",
       " 0.0077527952,\n",
       " -0.020093959,\n",
       " -0.0069665224,\n",
       " 0.014997863,\n",
       " 0.012109376,\n",
       " -0.02253598,\n",
       " -0.011384729,\n",
       " 0.012960192,\n",
       " -0.009098214,\n",
       " -0.023569591,\n",
       " 0.0065596905,\n",
       " 0.0048632794,\n",
       " 0.012545182,\n",
       " -0.0114417095,\n",
       " 0.018537825,\n",
       " 0.004694302,\n",
       " -0.001858589,\n",
       " 0.017551703,\n",
       " 0.013601088,\n",
       " 0.00036422408,\n",
       " -0.00496544,\n",
       " 0.0007764104,\n",
       " -0.0021145146,\n",
       " -0.0025209219,\n",
       " 0.0052762,\n",
       " 0.028677277,\n",
       " -0.0087252045,\n",
       " -0.0077612833,\n",
       " -0.011003691,\n",
       " 0.0116443485,\n",
       " 0.003039378,\n",
       " -0.0114321215,\n",
       " -0.0007906829,\n",
       " 0.017309314,\n",
       " -0.006212305,\n",
       " -0.013919309,\n",
       " -0.020574378,\n",
       " -0.0014623936,\n",
       " 0.0010384355,\n",
       " 0.015927466,\n",
       " -0.0060821767,\n",
       " 0.010868445,\n",
       " -0.004875869,\n",
       " -0.0021393073,\n",
       " 0.002995735,\n",
       " 0.018021978,\n",
       " -0.0173647,\n",
       " -0.006744075,\n",
       " -0.00681134,\n",
       " -0.0030378255,\n",
       " -0.0020214047,\n",
       " 0.012312113,\n",
       " -0.013801525,\n",
       " -0.0042072,\n",
       " 0.007100562,\n",
       " 0.006814276,\n",
       " -0.028928017,\n",
       " 0.016432907,\n",
       " -0.014996979,\n",
       " -0.0088819135,\n",
       " -0.015389654,\n",
       " -0.018313901,\n",
       " 0.0025243715,\n",
       " -0.0022878808,\n",
       " -0.008334276,\n",
       " 0.004270661,\n",
       " -0.021205911,\n",
       " 0.0024921885,\n",
       " 0.020744996,\n",
       " 0.0077493833,\n",
       " 0.001163762,\n",
       " 0.01655565,\n",
       " 0.02888859,\n",
       " -0.014638063,\n",
       " 0.0143087935,\n",
       " 0.017085548,\n",
       " -0.015538086,\n",
       " 0.0065257605,\n",
       " -0.03541863,\n",
       " 0.0076545267,\n",
       " 0.017355803,\n",
       " 0.016074102,\n",
       " 0.0045845024,\n",
       " -0.0014512083,\n",
       " 0.015720813,\n",
       " 0.0064040716,\n",
       " 0.013567715,\n",
       " -0.0077034663,\n",
       " 0.004389791,\n",
       " -0.017550403,\n",
       " -0.01872739,\n",
       " -0.01394701,\n",
       " -0.012491685,\n",
       " 0.008569232,\n",
       " -0.0038134411,\n",
       " -0.014355149,\n",
       " -0.004047451,\n",
       " 0.013354758,\n",
       " -0.0040261983,\n",
       " -0.033516172,\n",
       " -0.005299581,\n",
       " -0.0035405487,\n",
       " 0.018932806,\n",
       " -0.009336371,\n",
       " 0.0054086447,\n",
       " 0.0058133774,\n",
       " 0.0011451396,\n",
       " -0.008325446,\n",
       " -0.018058712,\n",
       " -0.016882168,\n",
       " 0.0047153677,\n",
       " -0.040135037,\n",
       " 0.0022665784,\n",
       " -0.0009745521,\n",
       " -0.009677974,\n",
       " -0.02064188,\n",
       " -0.003109772,\n",
       " -0.022142759,\n",
       " 0.0061041117,\n",
       " 0.009369077,\n",
       " 0.019327303,\n",
       " -0.03195895,\n",
       " -0.023624115,\n",
       " 0.006868687,\n",
       " -0.006720532,\n",
       " -0.0016325519,\n",
       " 0.0014481829,\n",
       " 0.010658259,\n",
       " -0.012588841,\n",
       " -0.0011795333,\n",
       " -0.024496963,\n",
       " -0.01916339,\n",
       " 0.008762353,\n",
       " 0.020060576,\n",
       " 0.003645316,\n",
       " 0.009428773,\n",
       " -0.014275847,\n",
       " 0.006113149,\n",
       " 0.043337792,\n",
       " -0.033473454,\n",
       " 0.009459732,\n",
       " -0.011613918,\n",
       " 0.014476963,\n",
       " -0.0028846876,\n",
       " 0.0045821425,\n",
       " -0.010439021,\n",
       " 0.011308408,\n",
       " 0.004682825,\n",
       " -0.016853096,\n",
       " -0.0048432006,\n",
       " 0.018963005,\n",
       " -0.016758798,\n",
       " -0.012962218,\n",
       " 0.0058985385,\n",
       " -0.0027504452,\n",
       " 0.00040543682,\n",
       " 0.010562921,\n",
       " 0.011912685,\n",
       " -0.0043689306,\n",
       " -0.024460068,\n",
       " 0.013335078,\n",
       " 0.00082310115,\n",
       " 0.005534693,\n",
       " -0.0027320643,\n",
       " -0.0136926025,\n",
       " 0.02724081,\n",
       " 0.0193378,\n",
       " -0.0038841357,\n",
       " 0.015031758,\n",
       " -0.0037673055,\n",
       " 0.0029657586,\n",
       " 0.01233426,\n",
       " -0.00032735206,\n",
       " 0.018588033,\n",
       " 0.018179787,\n",
       " 0.005524338,\n",
       " 0.018180145,\n",
       " -0.010372563,\n",
       " -0.024187017,\n",
       " -0.032187425,\n",
       " 0.0037965723,\n",
       " -0.004927428,\n",
       " 0.00839498,\n",
       " -0.033784144,\n",
       " 0.05060395,\n",
       " 0.00015481569,\n",
       " -0.004643537,\n",
       " -0.0009424327,\n",
       " -0.024200352,\n",
       " -0.022717869,\n",
       " 0.0043845973,\n",
       " -0.01810041,\n",
       " -0.0033388606,\n",
       " -0.013312051,\n",
       " -0.008389946,\n",
       " 0.004432113,\n",
       " -0.029061636,\n",
       " -0.024967374,\n",
       " -0.010579919,\n",
       " 0.0041041467,\n",
       " -0.00409745,\n",
       " 0.008332839,\n",
       " 0.0085109845,\n",
       " -0.011287033,\n",
       " -0.012098431,\n",
       " -0.029510647,\n",
       " -0.011038535,\n",
       " 0.003474275,\n",
       " -0.0009498622,\n",
       " 0.006667119,\n",
       " 0.009005414,\n",
       " 0.03478161,\n",
       " -0.018191235,\n",
       " 0.005190089,\n",
       " 0.023131793,\n",
       " -0.008907716,\n",
       " -0.00033975567,\n",
       " -0.01835859,\n",
       " -0.016291203,\n",
       " 0.026201846,\n",
       " -0.00930876,\n",
       " -0.022370791,\n",
       " -0.021615565,\n",
       " 0.0017130827,\n",
       " 0.023306401,\n",
       " 0.002830385,\n",
       " -0.010213967,\n",
       " -0.0044740294,\n",
       " -0.0146791,\n",
       " -0.016821204,\n",
       " -0.0105355475,\n",
       " -0.017647494,\n",
       " -0.015769886,\n",
       " 0.0083615575,\n",
       " -0.021874133,\n",
       " -0.015088875,\n",
       " 0.003666692,\n",
       " 0.0038773913,\n",
       " -0.003523522,\n",
       " 0.008928924,\n",
       " 0.0017057594,\n",
       " 0.0030592703,\n",
       " 0.011097571,\n",
       " 0.021339782,\n",
       " -0.004924632,\n",
       " 0.006694494,\n",
       " 0.01717259,\n",
       " -0.006143368,\n",
       " -0.0054673343,\n",
       " 0.012439391,\n",
       " -0.0019950613,\n",
       " 0.008459407,\n",
       " -0.008847623,\n",
       " 0.002557658,\n",
       " -0.0014952043,\n",
       " 0.0013999775,\n",
       " -0.0004742725,\n",
       " -0.0004987505,\n",
       " 0.009163089,\n",
       " -0.0192308,\n",
       " 0.008254415,\n",
       " -0.010376044,\n",
       " 0.0033804334,\n",
       " -0.0065262713,\n",
       " -0.004229829,\n",
       " -0.020289663,\n",
       " 0.0014478039,\n",
       " -0.0067615914,\n",
       " 0.0036773488,\n",
       " 0.004032401,\n",
       " -0.010327661,\n",
       " -0.0062848255,\n",
       " 0.0014208859,\n",
       " 0.016084686,\n",
       " -0.0062501403,\n",
       " -0.0043010456,\n",
       " 0.017354717,\n",
       " 0.01577708,\n",
       " -0.007104817,\n",
       " -0.042106546,\n",
       " -0.0010331697,\n",
       " -0.0015226692,\n",
       " 0.015402673,\n",
       " 0.0008826728,\n",
       " 0.017047448,\n",
       " -0.01954544,\n",
       " 0.0074552377,\n",
       " 0.002140485,\n",
       " -0.007355778,\n",
       " -0.01439716,\n",
       " 0.0015793577,\n",
       " -9.3352435e-05,\n",
       " -0.004618786,\n",
       " -0.014832917,\n",
       " -0.01797933,\n",
       " -0.0015177603,\n",
       " -0.00420104,\n",
       " 0.004798466,\n",
       " -0.00820001,\n",
       " -0.01562775,\n",
       " -0.015439957,\n",
       " -0.0072056795,\n",
       " 0.0029225294,\n",
       " 0.01369823,\n",
       " 0.012745108,\n",
       " 0.0077971155,\n",
       " -0.010174513,\n",
       " -0.03396911,\n",
       " -0.034330014,\n",
       " 0.0012944811,\n",
       " 0.022894405,\n",
       " 0.028595494,\n",
       " 0.02462204,\n",
       " -0.010306544,\n",
       " 0.01877223,\n",
       " 0.0042405776,\n",
       " 0.0404896,\n",
       " 0.017183008,\n",
       " 0.005969517,\n",
       " -0.0138887465,\n",
       " -0.016962152,\n",
       " -0.012314116,\n",
       " -0.025571894,\n",
       " -0.0005041389,\n",
       " -0.009819483,\n",
       " -0.023897175,\n",
       " -0.014212313,\n",
       " 0.00476425,\n",
       " 0.01770301,\n",
       " -0.0068718647,\n",
       " 0.010316637,\n",
       " 0.012845838,\n",
       " 0.010426355,\n",
       " -0.012433794,\n",
       " -0.031139532,\n",
       " -0.009318175,\n",
       " 0.00037540676,\n",
       " 0.01660189,\n",
       " 0.005709442,\n",
       " -0.001570457,\n",
       " -0.02726683,\n",
       " 0.00275702,\n",
       " 0.008091729,\n",
       " 0.012129675,\n",
       " -0.007500309,\n",
       " -0.0029638694,\n",
       " -0.0074169007,\n",
       " -0.019297777,\n",
       " 0.0018302401,\n",
       " 0.012677877,\n",
       " 0.029511258,\n",
       " -0.0026087547,\n",
       " -0.018167714,\n",
       " 0.011452545,\n",
       " 0.0044625774,\n",
       " 0.034912344,\n",
       " 0.009688774,\n",
       " -0.0007546884,\n",
       " -0.0009830594,\n",
       " -0.0062623704,\n",
       " -0.00300318,\n",
       " -0.005076245,\n",
       " -0.012287924,\n",
       " 0.0055133356,\n",
       " -0.002628575,\n",
       " 0.02744624,\n",
       " -0.003627778,\n",
       " -0.02381301,\n",
       " -0.0044691106,\n",
       " -0.00933618,\n",
       " 0.010356585,\n",
       " -0.00911051,\n",
       " 0.013342,\n",
       " -0.0075125885,\n",
       " -0.043215904,\n",
       " 0.008859203,\n",
       " -0.004593675,\n",
       " 0.020995757,\n",
       " 0.019211022,\n",
       " 0.009940578,\n",
       " 0.0005603859,\n",
       " 0.021222312,\n",
       " 0.0061680535,\n",
       " -0.006422411,\n",
       " 0.0029297548,\n",
       " -0.02514007,\n",
       " 0.012792083,\n",
       " 0.013927791,\n",
       " -0.0036498492,\n",
       " 0.008178143,\n",
       " -0.014303961,\n",
       " 0.02375725,\n",
       " -0.012352796,\n",
       " 0.008301642,\n",
       " 0.0037537846,\n",
       " 0.030293075,\n",
       " -0.0026772926,\n",
       " -0.014001349,\n",
       " -0.021120125,\n",
       " -0.017537424,\n",
       " 0.019588197,\n",
       " 0.0012349141,\n",
       " -0.002445144,\n",
       " -0.0016602526,\n",
       " 0.0050339364,\n",
       " -6.439418e-05,\n",
       " 0.0075712563,\n",
       " 0.0025147272,\n",
       " -0.0011527777,\n",
       " -0.013533156,\n",
       " 0.007464205,\n",
       " 0.0007748497,\n",
       " -0.014547435,\n",
       " -0.010704257,\n",
       " -0.015235599,\n",
       " -0.01183403,\n",
       " 0.0104614785,\n",
       " 0.0058426377,\n",
       " 0.023208996,\n",
       " -0.0029501875,\n",
       " -0.008863418,\n",
       " -0.005422535,\n",
       " 0.030339718,\n",
       " -0.010073164,\n",
       " 0.013672532,\n",
       " -0.023419905,\n",
       " -0.014577928,\n",
       " -0.006000707,\n",
       " -0.00046997273,\n",
       " 0.019259598,\n",
       " -0.013195578,\n",
       " -0.0063088187,\n",
       " -0.003055408,\n",
       " 0.0034985042,\n",
       " 0.012432914,\n",
       " 0.0005433651,\n",
       " -0.027153479,\n",
       " -0.0006864984,\n",
       " 0.008675739,\n",
       " 0.013229335,\n",
       " -0.011895853,\n",
       " -0.007120663,\n",
       " -0.010695085,\n",
       " -0.0044922177,\n",
       " 0.0031378109,\n",
       " 0.004881158,\n",
       " 0.00062767253,\n",
       " 0.0044913385,\n",
       " 0.011881872,\n",
       " -0.0203478,\n",
       " -0.023954535,\n",
       " 0.032533173,\n",
       " -0.011526842,\n",
       " -0.038281582,\n",
       " 0.0053978483,\n",
       " 0.00519491,\n",
       " -0.028424375,\n",
       " 0.0083298255,\n",
       " 0.011972887,\n",
       " -0.020307088,\n",
       " 0.021258047,\n",
       " 0.01437382,\n",
       " 0.011437777,\n",
       " 0.004122678,\n",
       " 0.022056421,\n",
       " 0.005323304,\n",
       " 0.0046045617,\n",
       " -0.0025476147,\n",
       " 0.0061766338,\n",
       " -0.010188842,\n",
       " -0.008932728,\n",
       " -0.015295602,\n",
       " 0.0043931324,\n",
       " -0.01193817,\n",
       " 0.041655283,\n",
       " 0.024267808,\n",
       " -0.010985397,\n",
       " 0.0058779283,\n",
       " 0.0020830913,\n",
       " -0.025404748,\n",
       " 0.0065288884,\n",
       " 0.012708749,\n",
       " -0.035408426,\n",
       " 0.0035863721,\n",
       " -0.014281846,\n",
       " 0.00097701,\n",
       " -0.0035867312,\n",
       " 0.019282363,\n",
       " -0.0048792786,\n",
       " 0.006596392,\n",
       " 0.010758243,\n",
       " 0.011460354,\n",
       " 0.006896488,\n",
       " 0.022434179,\n",
       " 0.0045985742,\n",
       " 0.00519753,\n",
       " -0.011763637,\n",
       " -0.003916099,\n",
       " -0.03086002,\n",
       " -0.005070878,\n",
       " 0.00879905,\n",
       " -0.02593776,\n",
       " 0.00039545321,\n",
       " 0.011970213,\n",
       " 0.017089171,\n",
       " 0.018673968,\n",
       " -0.026637213,\n",
       " -0.0284505,\n",
       " -0.018370247,\n",
       " 0.011945254,\n",
       " -0.020020904,\n",
       " -0.008648045,\n",
       " -0.004812292,\n",
       " -0.029936332,\n",
       " -0.008696092,\n",
       " -0.010061937,\n",
       " -0.0075243986,\n",
       " 0.034005906,\n",
       " -0.0011022323,\n",
       " 0.009560675,\n",
       " -0.01892392,\n",
       " 0.010513112,\n",
       " 0.0043077413,\n",
       " 0.016519729,\n",
       " 0.005993195,\n",
       " 0.012569826,\n",
       " 0.0137807755,\n",
       " 0.0025787018,\n",
       " -0.0045887744,\n",
       " 0.006410141,\n",
       " -0.017392702,\n",
       " -0.02565552,\n",
       " -0.008455895,\n",
       " 0.00876434,\n",
       " 0.016971186,\n",
       " 0.0055932584,\n",
       " -0.017435433,\n",
       " 0.0063005323,\n",
       " 0.0190266,\n",
       " 0.015918788,\n",
       " -0.002990445,\n",
       " -0.00435409,\n",
       " -0.018981634,\n",
       " -0.012564343,\n",
       " 0.013250293,\n",
       " 0.005499503,\n",
       " 0.020769281,\n",
       " 0.016955055,\n",
       " -0.0031955866,\n",
       " 0.0104887085,\n",
       " -0.0012766075,\n",
       " 0.006264305,\n",
       " -0.03721616,\n",
       " 0.013052093,\n",
       " 0.0034166295,\n",
       " 0.020869575,\n",
       " 0.00842905,\n",
       " 0.016806608,\n",
       " -0.020518133,\n",
       " -0.0061663804,\n",
       " 0.001022013,\n",
       " 0.0025960982,\n",
       " 0.039736126,\n",
       " -0.014686621,\n",
       " -0.014631287,\n",
       " 0.006687145,\n",
       " -0.013336505,\n",
       " 0.027340513,\n",
       " 0.0038424218,\n",
       " 0.004155908,\n",
       " -0.008257354,\n",
       " -0.0076033655,\n",
       " -0.019891845,\n",
       " -0.01591167,\n",
       " 0.010153292,\n",
       " -0.015946306,\n",
       " 0.0066623213]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_test[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Başlangıç değerleri\n",
    "np.random.seed(42)\n",
    "# Ağırlık ve biasların başlangıç değerleri\n",
    "agirliklar = [np.random.randn(girdi_ozellik_sayisi, gizli_katman_noron_sayisi), \n",
    "              np.random.randn(gizli_katman_noron_sayisi, sinif_sayisi)]\n",
    "biaslar = [np.random.randn(gizli_katman_noron_sayisi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 256), (256, 2), (256,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agirliklar[0].shape, agirliklar[1].shape, biaslar[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropy kaybı 1 iterasyondan sonra 0.60681545\n",
      "Eğitim doğruluğu 1 iterasyondan sonra 66.3986%\n",
      "gizli_katman_agirliklari_gW0=0.9903 cikis_katman_agirliklari_gW1=0.9906 gizli_katman_biaslari_gb0=0.9921\n",
      "ogrenme_orani_etaW0=0.5022 ogrenme_orani_etaW1=0.5021 ogrenme_orani_etab0=0.5017\n",
      "|agirlik_turevleri[0]|=0.15875 |agirlik_turevleri[1]|=0.24493 |bias_turevleri[0]|=0.45914 \n",
      "\n",
      "Cross-entropy kaybı 6 iterasyondan sonra 0.60885146\n",
      "Eğitim doğruluğu 6 iterasyondan sonra 64.0673%\n",
      "gizli_katman_agirliklari_gW0=0.9522 cikis_katman_agirliklari_gW1=0.9538 gizli_katman_biaslari_gb0=0.9609\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5117 ogrenme_orani_etab0=0.5098\n",
      "|agirlik_turevleri[0]|=0.15879 |agirlik_turevleri[1]|=0.24212 |bias_turevleri[0]|=0.45782 \n",
      "\n",
      "Cross-entropy kaybı 11 iterasyondan sonra 0.60942331\n",
      "Eğitim doğruluğu 11 iterasyondan sonra 65.9348%\n",
      "gizli_katman_agirliklari_gW0=0.9523 cikis_katman_agirliklari_gW1=0.9539 gizli_katman_biaslari_gb0=0.9617\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5117 ogrenme_orani_etab0=0.5096\n",
      "|agirlik_turevleri[0]|=0.16288 |agirlik_turevleri[1]|=0.24397 |bias_turevleri[0]|=0.47123 \n",
      "\n",
      "Cross-entropy kaybı 16 iterasyondan sonra 0.60780636\n",
      "Eğitim doğruluğu 16 iterasyondan sonra 64.1513%\n",
      "gizli_katman_agirliklari_gW0=0.9523 cikis_katman_agirliklari_gW1=0.9539 gizli_katman_biaslari_gb0=0.9618\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5117 ogrenme_orani_etab0=0.5096\n",
      "|agirlik_turevleri[0]|=0.16151 |agirlik_turevleri[1]|=0.23986 |bias_turevleri[0]|=0.46569 \n",
      "\n",
      "Cross-entropy kaybı 21 iterasyondan sonra 0.60581408\n",
      "Eğitim doğruluğu 21 iterasyondan sonra 66.4665%\n",
      "gizli_katman_agirliklari_gW0=0.9522 cikis_katman_agirliklari_gW1=0.9537 gizli_katman_biaslari_gb0=0.9614\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5117 ogrenme_orani_etab0=0.5097\n",
      "|agirlik_turevleri[0]|=0.15911 |agirlik_turevleri[1]|=0.23222 |bias_turevleri[0]|=0.46033 \n",
      "\n",
      "Cross-entropy kaybı 26 iterasyondan sonra 0.60630087\n",
      "Eğitim doğruluğu 26 iterasyondan sonra 64.2903%\n",
      "gizli_katman_agirliklari_gW0=0.9522 cikis_katman_agirliklari_gW1=0.9536 gizli_katman_biaslari_gb0=0.9615\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5117 ogrenme_orani_etab0=0.5097\n",
      "|agirlik_turevleri[0]|=0.16139 |agirlik_turevleri[1]|=0.23305 |bias_turevleri[0]|=0.46539 \n",
      "\n",
      "Cross-entropy kaybı 31 iterasyondan sonra 0.60654964\n",
      "Eğitim doğruluğu 31 iterasyondan sonra 66.2475%\n",
      "gizli_katman_agirliklari_gW0=0.9523 cikis_katman_agirliklari_gW1=0.9536 gizli_katman_biaslari_gb0=0.9619\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5117 ogrenme_orani_etab0=0.5096\n",
      "|agirlik_turevleri[0]|=0.16388 |agirlik_turevleri[1]|=0.23279 |bias_turevleri[0]|=0.47422 \n",
      "\n",
      "Cross-entropy kaybı 36 iterasyondan sonra 0.60575177\n",
      "Eğitim doğruluğu 36 iterasyondan sonra 64.3122%\n",
      "gizli_katman_agirliklari_gW0=0.9523 cikis_katman_agirliklari_gW1=0.9536 gizli_katman_biaslari_gb0=0.9620\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5117 ogrenme_orani_etab0=0.5095\n",
      "|agirlik_turevleri[0]|=0.16408 |agirlik_turevleri[1]|=0.23135 |bias_turevleri[0]|=0.47318 \n",
      "\n",
      "Cross-entropy kaybı 41 iterasyondan sonra 0.60444725\n",
      "Eğitim doğruluğu 41 iterasyondan sonra 66.5126%\n",
      "gizli_katman_agirliklari_gW0=0.9523 cikis_katman_agirliklari_gW1=0.9535 gizli_katman_biaslari_gb0=0.9619\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5118 ogrenme_orani_etab0=0.5095\n",
      "|agirlik_turevleri[0]|=0.16280 |agirlik_turevleri[1]|=0.22589 |bias_turevleri[0]|=0.47111 \n",
      "\n",
      "Cross-entropy kaybı 46 iterasyondan sonra 0.60434099\n",
      "Eğitim doğruluğu 46 iterasyondan sonra 64.4592%\n",
      "gizli_katman_agirliklari_gW0=0.9523 cikis_katman_agirliklari_gW1=0.9535 gizli_katman_biaslari_gb0=0.9619\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5118 ogrenme_orani_etab0=0.5095\n",
      "|agirlik_turevleri[0]|=0.16407 |agirlik_turevleri[1]|=0.22574 |bias_turevleri[0]|=0.47315 \n",
      "\n",
      "Cross-entropy kaybı 51 iterasyondan sonra 0.60427205\n",
      "Eğitim doğruluğu 51 iterasyondan sonra 66.5077%\n",
      "gizli_katman_agirliklari_gW0=0.9523 cikis_katman_agirliklari_gW1=0.9535 gizli_katman_biaslari_gb0=0.9621\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5118 ogrenme_orani_etab0=0.5095\n",
      "|agirlik_turevleri[0]|=0.16529 |agirlik_turevleri[1]|=0.22409 |bias_turevleri[0]|=0.47838 \n",
      "\n",
      "Cross-entropy kaybı 56 iterasyondan sonra 0.60390119\n",
      "Eğitim doğruluğu 56 iterasyondan sonra 64.4835%\n",
      "gizli_katman_agirliklari_gW0=0.9523 cikis_katman_agirliklari_gW1=0.9534 gizli_katman_biaslari_gb0=0.9622\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5118 ogrenme_orani_etab0=0.5095\n",
      "|agirlik_turevleri[0]|=0.16628 |agirlik_turevleri[1]|=0.22382 |bias_turevleri[0]|=0.47959 \n",
      "\n",
      "Cross-entropy kaybı 61 iterasyondan sonra 0.60322891\n",
      "Eğitim doğruluğu 61 iterasyondan sonra 66.6128%\n",
      "gizli_katman_agirliklari_gW0=0.9523 cikis_katman_agirliklari_gW1=0.9534 gizli_katman_biaslari_gb0=0.9623\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5118 ogrenme_orani_etab0=0.5094\n",
      "|agirlik_turevleri[0]|=0.16597 |agirlik_turevleri[1]|=0.22027 |bias_turevleri[0]|=0.48039 \n",
      "\n",
      "Cross-entropy kaybı 66 iterasyondan sonra 0.60281842\n",
      "Eğitim doğruluğu 66 iterasyondan sonra 64.6128%\n",
      "gizli_katman_agirliklari_gW0=0.9523 cikis_katman_agirliklari_gW1=0.9534 gizli_katman_biaslari_gb0=0.9623\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5118 ogrenme_orani_etab0=0.5094\n",
      "|agirlik_turevleri[0]|=0.16680 |agirlik_turevleri[1]|=0.21979 |bias_turevleri[0]|=0.48109 \n",
      "\n",
      "Cross-entropy kaybı 71 iterasyondan sonra 0.60271138\n",
      "Eğitim doğruluğu 71 iterasyondan sonra 66.6330%\n",
      "gizli_katman_agirliklari_gW0=0.9524 cikis_katman_agirliklari_gW1=0.9533 gizli_katman_biaslari_gb0=0.9624\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5118 ogrenme_orani_etab0=0.5094\n",
      "|agirlik_turevleri[0]|=0.16741 |agirlik_turevleri[1]|=0.21764 |bias_turevleri[0]|=0.48459 \n",
      "\n",
      "Cross-entropy kaybı 76 iterasyondan sonra 0.60231889\n",
      "Eğitim doğruluğu 76 iterasyondan sonra 64.6241%\n",
      "gizli_katman_agirliklari_gW0=0.9524 cikis_katman_agirliklari_gW1=0.9533 gizli_katman_biaslari_gb0=0.9625\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5118 ogrenme_orani_etab0=0.5094\n",
      "|agirlik_turevleri[0]|=0.16846 |agirlik_turevleri[1]|=0.21765 |bias_turevleri[0]|=0.48592 \n",
      "\n",
      "Cross-entropy kaybı 81 iterasyondan sonra 0.60191393\n",
      "Eğitim doğruluğu 81 iterasyondan sonra 66.6928%\n",
      "gizli_katman_agirliklari_gW0=0.9524 cikis_katman_agirliklari_gW1=0.9533 gizli_katman_biaslari_gb0=0.9626\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5118 ogrenme_orani_etab0=0.5094\n",
      "|agirlik_turevleri[0]|=0.16829 |agirlik_turevleri[1]|=0.21476 |bias_turevleri[0]|=0.48718 \n",
      "\n",
      "Cross-entropy kaybı 86 iterasyondan sonra 0.60153311\n",
      "Eğitim doğruluğu 86 iterasyondan sonra 64.6968%\n",
      "gizli_katman_agirliklari_gW0=0.9524 cikis_katman_agirliklari_gW1=0.9532 gizli_katman_biaslari_gb0=0.9626\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5118 ogrenme_orani_etab0=0.5093\n",
      "|agirlik_turevleri[0]|=0.16928 |agirlik_turevleri[1]|=0.21459 |bias_turevleri[0]|=0.48833 \n",
      "\n",
      "Cross-entropy kaybı 91 iterasyondan sonra 0.60144698\n",
      "Eğitim doğruluğu 91 iterasyondan sonra 66.7081%\n",
      "gizli_katman_agirliklari_gW0=0.9524 cikis_katman_agirliklari_gW1=0.9532 gizli_katman_biaslari_gb0=0.9627\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5119 ogrenme_orani_etab0=0.5093\n",
      "|agirlik_turevleri[0]|=0.16963 |agirlik_turevleri[1]|=0.21263 |bias_turevleri[0]|=0.49108 \n",
      "\n",
      "Cross-entropy kaybı 96 iterasyondan sonra 0.60096402\n",
      "Eğitim doğruluğu 96 iterasyondan sonra 64.7324%\n",
      "gizli_katman_agirliklari_gW0=0.9524 cikis_katman_agirliklari_gW1=0.9532 gizli_katman_biaslari_gb0=0.9628\n",
      "ogrenme_orani_etaW0=0.5121 ogrenme_orani_etaW1=0.5119 ogrenme_orani_etab0=0.5093\n",
      "|agirlik_turevleri[0]|=0.17051 |agirlik_turevleri[1]|=0.21238 |bias_turevleri[0]|=0.49190 \n",
      "\n",
      "Son cross-entropy kaybı 0.59924157\n",
      "Son eğitim doğruluğu 64.9465%\n",
      "CPU times: user 22min 58s, sys: 8min 12s, total: 31min 10s\n",
      "Wall time: 3min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Başlangıç değerleri\n",
    "gizli_katman_agirliklari_gW0 = cikis_katman_agirliklari_gW1 = gizli_katman_biaslari_gb0 = 1\n",
    "\n",
    "# Eğitim döngüsü\n",
    "for iterasyon in range(toplam_iterasyon_sayisi):\n",
    "    # Ağırlık ve biasların türevlerini geri yayılım fonksiyonuyla hesapla\n",
    "    agirlik_turevleri, bias_turevleri = geri_yayilim(agirliklar, biaslar, X_egitim, y_egitim, duzenleme_katsayisi_alpha)\n",
    "    \n",
    "    # Gizli katman ağırlıkları için RMSprop güncellemesi\n",
    "    gizli_katman_agirliklari_gW0 = rmsprop_gamma * gizli_katman_agirliklari_gW0 + (1 - rmsprop_gamma) * np.sum(agirlik_turevleri[0]**2)\n",
    "    ogrenme_orani_etaW0 = ogrenme_orani_eta / np.sqrt(gizli_katman_agirliklari_gW0 + rmsprop_eps)\n",
    "    agirliklar[0] -= ogrenme_orani_etaW0 * agirlik_turevleri[0]\n",
    "    \n",
    "    # Çıkış katman ağırlıkları için RMSprop güncellemesi\n",
    "    cikis_katman_agirliklari_gW1 = rmsprop_gamma * cikis_katman_agirliklari_gW1 + (1 - rmsprop_gamma) * np.sum(agirlik_turevleri[1]**2)\n",
    "    ogrenme_orani_etaW1 = ogrenme_orani_eta / np.sqrt(cikis_katman_agirliklari_gW1 + rmsprop_eps)\n",
    "    agirliklar[1] -= ogrenme_orani_etaW1 * agirlik_turevleri[1]\n",
    "    \n",
    "    # Gizli katman biasları için RMSprop güncellemesi\n",
    "    gizli_katman_biaslari_gb0 = rmsprop_gamma * gizli_katman_biaslari_gb0 + (1 - rmsprop_gamma) * np.sum(bias_turevleri[0]**2)\n",
    "    ogrenme_orani_etab0 = ogrenme_orani_eta / np.sqrt(gizli_katman_biaslari_gb0 + rmsprop_eps)\n",
    "    biaslar[0] -= ogrenme_orani_etab0 * bias_turevleri[0]\n",
    "    \n",
    "    if iterasyon % 5 == 0:\n",
    "      # Durum kontrolü 1: Kayıp ve doğruluk hesaplama\n",
    "      tahminler = tahmin_et(X_egitim, agirliklar, biaslar)\n",
    "      print(\"Cross-entropy kaybı\", iterasyon + 1, \"iterasyondan sonra {:.8}\".format(\n",
    "            kayip_hesapla(tahminler, y_egitim)))\n",
    "      print(\"Eğitim doğruluğu\", iterasyon + 1, \"iterasyondan sonra {:.4%}\".format( \n",
    "            np.mean(np.argmax(tahminler, axis=1) == y_egitim)))\n",
    "      \n",
    "      # Durum kontrolü 2: RMSprop değerlerinin çıktısını yazdırma\n",
    "      print(\"gizli_katman_agirliklari_gW0={:.4f} cikis_katman_agirliklari_gW1={:.4f} gizli_katman_biaslari_gb0={:.4f}\\n\"\n",
    "            \"ogrenme_orani_etaW0={:.4f} ogrenme_orani_etaW1={:.4f} ogrenme_orani_etab0={:.4f}\"\n",
    "            .format(gizli_katman_agirliklari_gW0, cikis_katman_agirliklari_gW1, gizli_katman_biaslari_gb0, \n",
    "                    ogrenme_orani_etaW0, ogrenme_orani_etaW1, ogrenme_orani_etab0))\n",
    "      \n",
    "      # Durum kontrolü 3: Ağırlık ve bias türevlerinin normlarını yazdırma\n",
    "      print(\"|agirlik_turevleri[0]|={:.5f} |agirlik_turevleri[1]|={:.5f} |bias_turevleri[0]|={:.5f}\"\n",
    "            .format(np.linalg.norm(agirlik_turevleri[0]), np.linalg.norm(agirlik_turevleri[1]), np.linalg.norm(bias_turevleri[0])), \"\\n\")\n",
    "      \n",
    "      # RMSprop değerlerini sıfırlama\n",
    "      gizli_katman_agirliklari_gW0 = cikis_katman_agirliklari_gW1 = gizli_katman_biaslari_gb0 = 1\n",
    "\n",
    "# Son tahminler ve sonuçların yazdırılması\n",
    "son_tahminler = tahmin_et(X_egitim, agirliklar, biaslar)\n",
    "print(\"Son cross-entropy kaybı {:.8}\".format(kayip_hesapla(son_tahminler, y_egitim)))\n",
    "print(\"Son eğitim doğruluğu {:.4%}\".format(np.mean(np.argmax(son_tahminler, axis=1) == y_egitim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 63.6000%\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "y_pred_test = np.argmax(tahmin_et(X_test, agirliklar, biaslar), axis=1)\n",
    "print(\"Test accuracy is {:.4%}\".format(np.mean(y_pred_test == y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tr_token_cosmos_mapping.json') as f:\n",
    "    token_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30158"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alibayram/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "cosmos_model = GPT2LMHeadModel.from_pretrained(\"ytu-ce-cosmos/turkish-gpt2\")\n",
    "cosmos_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554df4374c3e4bf8be8aa0301a6f2998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gemma2Model(\n",
       "  (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
       "  (layers): ModuleList(\n",
       "    (0-25): 26 x Gemma2DecoderLayer(\n",
       "      (self_attn): Gemma2Attention(\n",
       "        (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
       "        (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
       "        (rotary_emb): Gemma2RotaryEmbedding()\n",
       "      )\n",
       "      (mlp): Gemma2MLP(\n",
       "        (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
       "        (act_fn): PytorchGELUTanh()\n",
       "      )\n",
       "      (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import Gemma2Model, Gemma2ForCausalLM\n",
    "\n",
    "gemma_model = Gemma2Model.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "gemma_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosmos_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# create an empty tensor to store the embeddings of the tokens shape (len(token_list), gemma_model.embed_tokens.weight.shape[1])\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m cosmos_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mcosmos_model\u001b[49m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mwte\u001b[38;5;241m.\u001b[39mweight\n\u001b[1;32m      4\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(token_list), cosmos_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      5\u001b[0m embeddings\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cosmos_model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# create an empty tensor to store the embeddings of the tokens shape (len(token_list), gemma_model.embed_tokens.weight.shape[1])\n",
    "cosmos_embeddings = cosmos_model.transformer.wte.weight\n",
    "embeddings = torch.zeros(len(token_list), cosmos_embeddings.shape[1])\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30158, 2304])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty tensor to store the embeddings of the tokens shape (len(token_list), gemma_model.embed_tokens.weight.shape[1])\n",
    "gemma_embeddings = gemma_model.embed_tokens.weight\n",
    "embeddings = torch.zeros(len(token_list), gemma_embeddings.shape[1])\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosmos_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token_list[\u001b[38;5;241m0\u001b[39m], \u001b[43mcosmos_embeddings\u001b[49m[\u001b[38;5;241m8714\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cosmos_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "token_list[0], cosmos_embeddings[8714]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmos_model.can_generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0067, -0.0076,  0.0065,  ...,  0.0170, -0.0135,  0.0192],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = gemma_embeddings[7871]\n",
    "e2 = gemma_embeddings[58714]\n",
    "\n",
    "e1 = e1 + e2\n",
    "average = e1 / 2\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosmos_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m index \u001b[38;5;241m=\u001b[39m token_map[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr_token_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m cosmos_token_ids \u001b[38;5;241m=\u001b[39m token_map[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosmos_token_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mcosmos_embeddings\u001b[49m[cosmos_token_ids[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m      8\u001b[0m sum_embedding \u001b[38;5;241m=\u001b[39m embedding\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cosmos_token_id \u001b[38;5;129;01min\u001b[39;00m cosmos_token_ids[\u001b[38;5;241m1\u001b[39m:]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cosmos_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "# for each token in the token_list, get the corresponding embedding from the gemma model and store it in the embeddings tensor\n",
    "# if there is more than one token in the token_list that maps to the same index, average the embeddings\n",
    "\n",
    "for token_map in token_list:\n",
    "    index = token_map['tr_token_id']\n",
    "    cosmos_token_ids = token_map['cosmos_token_ids']\n",
    "    embedding = cosmos_embeddings[cosmos_token_ids[0]]\n",
    "    sum_embedding = embedding\n",
    "    for cosmos_token_id in cosmos_token_ids[1:]:\n",
    "        embedding = embedding + cosmos_embeddings[cosmos_token_id]\n",
    "    if len(cosmos_token_ids) > 1:\n",
    "        embedding = embedding / len(cosmos_token_ids)        \n",
    "    embeddings[index] = embedding\n",
    "\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30158"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_of_zero_embeddings = 0\n",
    "for i in range(len(embeddings)):\n",
    "    if torch.all(embeddings[i] == 0):\n",
    "        count_of_zero_embeddings += 1\n",
    "count_of_zero_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings tensor to 3 different files\n",
    "order = 0\n",
    "for i in range(0, len(embeddings), 10100):\n",
    "    torch.save(embeddings[i:i+10100], f'tr_cosmos_embeddings_{order}.pt')\n",
    "    order += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma2Model(\n",
       "  (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
       "  (layers): ModuleList(\n",
       "    (0-25): 26 x Gemma2DecoderLayer(\n",
       "      (self_attn): Gemma2Attention(\n",
       "        (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
       "        (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
       "        (rotary_emb): Gemma2RotaryEmbedding()\n",
       "      )\n",
       "      (mlp): Gemma2MLP(\n",
       "        (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
       "        (act_fn): PytorchGELUTanh()\n",
       "      )\n",
       "      (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30158, 2304]), 30158)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change gemma2_model.embed_tokens.weight to the embeddings tensor\n",
    "gemma_model.embed_tokens.weight = torch.nn.Parameter(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_model.config.vocab_size = len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_model.save_pretrained(\"tr_gemma2_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8e47652ed646e3b2aa20786fe3a5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gemma2ForCausalLM(\n",
       "  (model): Gemma2Model(\n",
       "    (embed_tokens): Embedding(30158, 2304, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2Attention(\n",
       "          (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
       "          (rotary_emb): Gemma2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "          (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "          (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2304, out_features=30158, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma2_model = Gemma2ForCausalLM.from_pretrained(\"tr_gemma2_model\")\n",
    "gemma2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tr_tokenizer = AutoTokenizer.from_pretrained(\"alibayram/tr_tokenizer\")\n",
    "tr_tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vazife': 23130,\n",
       " 'Soydaş': 10179,\n",
       " 'Idea': 21996,\n",
       " 'isinden': 4822,\n",
       " 'Sön': 16120,\n",
       " 'ilçesi': 6547,\n",
       " 'ing': 1502,\n",
       " 'Demirle': 9012,\n",
       " 'çam': 25674,\n",
       " 'Abadi': 16870,\n",
       " 'Eurov': 3582,\n",
       " 'imren': 9547,\n",
       " 'lanması': 4245,\n",
       " 'amorf': 7701,\n",
       " 'Mazlum': 21406,\n",
       " 'Ayva': 22072,\n",
       " 'Ε': 317,\n",
       " 'üslup': 12884,\n",
       " 'Traş': 26903,\n",
       " 'Orhan': 6648,\n",
       " 'abone': 25438,\n",
       " 'Manuel': 25481,\n",
       " 'Tavsiye': 12814,\n",
       " 'galibiyet': 6794,\n",
       " 'asistan': 18870,\n",
       " 'kalker': 10059,\n",
       " 'Kamu': 8032,\n",
       " 'önemli': 2040,\n",
       " 'mahmuz': 26575,\n",
       " 'gevşek': 28937,\n",
       " 'Aman': 22982,\n",
       " 'Bezelye': 14278,\n",
       " 'Doğaçlama': 29802,\n",
       " 'ҡ': 446,\n",
       " 'Levent': 13232,\n",
       " 'esma': 19136,\n",
       " 'Çapar': 22434,\n",
       " 'Kaçamak': 22240,\n",
       " 'hısım': 27112,\n",
       " 'Pey': 13201,\n",
       " 'eradikasyon': 26666,\n",
       " 'tures': 6898,\n",
       " 'Kayak': 15490,\n",
       " 'Şekillen': 11255,\n",
       " 'Kümülüs': 27612,\n",
       " 'Zıt': 27371,\n",
       " 'kazağı': 25353,\n",
       " 'iliş': 6099,\n",
       " 'sın': 6055,\n",
       " 'Elvan': 30011,\n",
       " 'düş': 1731,\n",
       " 'Ortala': 19641,\n",
       " 'başlangıç': 16210,\n",
       " 'tab': 2380,\n",
       " 'Marş': 12173,\n",
       " 'kısrak': 25990,\n",
       " 'Bedeni': 19351,\n",
       " 'bekleme': 12946,\n",
       " '부': 1142,\n",
       " 'Kam': 3755,\n",
       " 'Beynelmilel': 23577,\n",
       " 'horasan': 17977,\n",
       " 'Racon': 23277,\n",
       " 'Bazı': 3880,\n",
       " 'ّ': 575,\n",
       " 'Adil': 11334,\n",
       " 'sarfet': 12760,\n",
       " 'Hediye': 23474,\n",
       " 'çul': 9719,\n",
       " 'kazein': 29195,\n",
       " 'boğmaca': 29577,\n",
       " 'manzara': 28392,\n",
       " 'mazlum': 27551,\n",
       " 'isine': 2862,\n",
       " 'ihtiva': 14497,\n",
       " 'keş': 2928,\n",
       " 'şarki': 7612,\n",
       " 'merhamet': 23743,\n",
       " 'önerge': 14045,\n",
       " 'Kelle': 15518,\n",
       " ';\"|': 6425,\n",
       " 'off': 3839,\n",
       " 'şansölye': 14602,\n",
       " 'neşe': 13373,\n",
       " 'Maşa': 24991,\n",
       " 'Temaşa': 16082,\n",
       " 'Kakao': 25138,\n",
       " 'hasıla': 21656,\n",
       " 'jigolo': 13385,\n",
       " 'anarşi': 21481,\n",
       " 'Çipura': 20057,\n",
       " 'Tesadüfen': 19974,\n",
       " 'usuf': 6341,\n",
       " 'tekli': 4430,\n",
       " 'Sahur': 19358,\n",
       " 'prefabrik': 8260,\n",
       " 'Ilen': 13629,\n",
       " 'macun': 9499,\n",
       " 'Kadar': 29652,\n",
       " 'Thomas': 5136,\n",
       " 'Verici': 15472,\n",
       " 'rakamla': 27841,\n",
       " 'Rahatsızlan': 22190,\n",
       " 'dinamo': 20588,\n",
       " 'harçlık': 19208,\n",
       " 'babayiğit': 25149,\n",
       " 'lili': 5941,\n",
       " 'dindar': 14245,\n",
       " 'kıble': 29718,\n",
       " 'Pazarla': 15216,\n",
       " 'armağan': 28962,\n",
       " 'Enkaz': 17211,\n",
       " 'gidon': 21829,\n",
       " 'derbi': 27816,\n",
       " 'varyasyon': 12894,\n",
       " 'tokalaş': 13183,\n",
       " 'Ümit': 19011,\n",
       " 'Baston': 8798,\n",
       " 'Obje': 25044,\n",
       " 'aydınlat': 27279,\n",
       " 'dola': 28336,\n",
       " 'kazasker': 10147,\n",
       " 'bibliyograf': 7399,\n",
       " 'ğa': 4677,\n",
       " 'Tazmin': 22674,\n",
       " 'zorunlu': 26160,\n",
       " 'pastel': 9492,\n",
       " 'Çöpçatan': 26472,\n",
       " 'Düzelti': 22769,\n",
       " 'onom': 2277,\n",
       " 'revan': 11189,\n",
       " 'Işlerlik': 9768,\n",
       " 'konsantrasyon': 16504,\n",
       " 'çöplük': 19888,\n",
       " 'ıspanak': 10587,\n",
       " 'Hayatı': 4697,\n",
       " 'postnişin': 20792,\n",
       " 'atmosfer': 20564,\n",
       " 'lokal': 20798,\n",
       " 'traverten': 16652,\n",
       " 'Tekke': 10934,\n",
       " 'Denklem': 24879,\n",
       " 'ico': 6826,\n",
       " 'Yarık': 13297,\n",
       " 'nakliyat': 19722,\n",
       " 'sağol': 19091,\n",
       " 'atandı': 5663,\n",
       " 'takımına': 5355,\n",
       " 'endüstriyel': 8149,\n",
       " 'yatış': 11788,\n",
       " 'muhtemel': 15209,\n",
       " '.)': 3588,\n",
       " 'ɾ': 275,\n",
       " 'Oylum': 15099,\n",
       " 'Sunucu': 17912,\n",
       " 'kinaye': 12111,\n",
       " 'bunu': 4290,\n",
       " 'duyurdu': 6838,\n",
       " '<unk>': 2,\n",
       " 'Mistisizm': 15808,\n",
       " 'fiyasko': 17818,\n",
       " 'Alıştırma': 22372,\n",
       " 'zirve': 20699,\n",
       " 'gergedan': 20821,\n",
       " 'Enstrümantal': 26855,\n",
       " 'Inisiyatif': 27011,\n",
       " 'eyvah': 29015,\n",
       " 'misil': 28093,\n",
       " '2021': 2804,\n",
       " 'göçü': 20224,\n",
       " 'Yokluk': 21643,\n",
       " 'asayiş': 9325,\n",
       " 'karakterize': 25114,\n",
       " '1946': 4825,\n",
       " '城': 967,\n",
       " 'hükümet': 10277,\n",
       " 'Salisilat': 19757,\n",
       " 'Aynen': 11353,\n",
       " 'stent': 21567,\n",
       " 'helik': 7260,\n",
       " 'Çörek': 8544,\n",
       " 'soyun': 21757,\n",
       " 'fink': 26675,\n",
       " 'geğir': 7917,\n",
       " 'imha': 17535,\n",
       " 'Türkü': 19168,\n",
       " 'bozkır': 13751,\n",
       " 'tıpkıbasım': 18801,\n",
       " 'Torak': 29236,\n",
       " 'Üretim': 28934,\n",
       " 'ḥ': 703,\n",
       " 'Dekoratör': 27962,\n",
       " 'Kumpas': 12378,\n",
       " 'elerden': 6541,\n",
       " 'Yalak': 24961,\n",
       " 'Süpermarket': 16685,\n",
       " 'sabit': 6077,\n",
       " 'öd': 12744,\n",
       " 'elbet': 16222,\n",
       " 'Icraat': 15824,\n",
       " 'mera': 14241,\n",
       " 'Fatih': 6034,\n",
       " 'keman': 28272,\n",
       " 'Duraksa': 19006,\n",
       " 'kapatma': 22771,\n",
       " 'Stad': 5233,\n",
       " 'sahife': 21062,\n",
       " 'Odakla': 24294,\n",
       " 'Teneffüs': 14493,\n",
       " 'Maslak': 14007,\n",
       " 'Beşik': 4769,\n",
       " 'Kitabe': 29997,\n",
       " 'Itilaf': 14189,\n",
       " 'Kaynakça': 1414,\n",
       " 'yıl': 1281,\n",
       " 'lub': 5247,\n",
       " 'arpej': 22582,\n",
       " 'Mamül': 22646,\n",
       " 'kıt': 25538,\n",
       " 'Baytar': 25446,\n",
       " 'ış': 1249,\n",
       " 'mukim': 16725,\n",
       " 'Mobilya': 12880,\n",
       " 'Mekan': 23755,\n",
       " 'ümüş': 3871,\n",
       " 'metalürji': 15123,\n",
       " 'Tersle': 14669,\n",
       " 'fotolitografi': 25216,\n",
       " 'besi': 6879,\n",
       " 'Seans': 10129,\n",
       " 'sök': 29620,\n",
       " 'Kereviz': 17508,\n",
       " 'savat': 22959,\n",
       " 'Ortodonti': 22341,\n",
       " 'maral': 13217,\n",
       " 'Plak': 13657,\n",
       " 'Sulh': 9749,\n",
       " 'Temas': 26988,\n",
       " 'orum': 6385,\n",
       " 'Umur': 27880,\n",
       " 'çeyiz': 26348,\n",
       " 'paleontoloji': 10447,\n",
       " 'Cambaz': 20211,\n",
       " 'kol': 2112,\n",
       " 'Aykırı': 29194,\n",
       " 'velayet': 18234,\n",
       " 'dekor': 28153,\n",
       " 'nakit': 29346,\n",
       " 'sarsım': 24736,\n",
       " 'Hematoloji': 11457,\n",
       " 'misina': 13103,\n",
       " 'Kariy': 4105,\n",
       " 'Ezeli': 16583,\n",
       " 'Derviş': 17859,\n",
       " 'E9E9': 1851,\n",
       " 'Cezai': 25282,\n",
       " 'դ': 471,\n",
       " 'şayka': 19043,\n",
       " 'Torbala': 28809,\n",
       " '之': 915,\n",
       " 'Hayırlı': 12885,\n",
       " 'hamiyet': 20782,\n",
       " 'millet': 23614,\n",
       " 'Roza': 18425,\n",
       " 'Şekerpare': 12078,\n",
       " 'üste': 22187,\n",
       " 'gıcık': 7656,\n",
       " 'metruk': 26608,\n",
       " 'bani': 19346,\n",
       " 'Işaretle': 27276,\n",
       " 'talimat': 8917,\n",
       " 'Devşirme': 8878,\n",
       " '1970': 3101,\n",
       " 'kotar': 21122,\n",
       " 'Posa': 17978,\n",
       " 'Yuvarlak': 25682,\n",
       " '兵': 937,\n",
       " 'Fotoelektrik': 15908,\n",
       " 'ic': 1335,\n",
       " 'anjiyo': 9267,\n",
       " 'Dol': 27288,\n",
       " 'unt': 5585,\n",
       " 'Çizik': 21229,\n",
       " 'şark': 3073,\n",
       " 'に': 841,\n",
       " 'azami': 13670,\n",
       " 'Birtakım': 16643,\n",
       " 'yığ': 11420,\n",
       " 'Sekte': 28964,\n",
       " 'yür': 2872,\n",
       " 'dinle': 29766,\n",
       " 'tayyare': 15874,\n",
       " 'çırpı': 23358,\n",
       " 'bolca': 21542,\n",
       " 'çıkı': 12966,\n",
       " 'kredile': 9199,\n",
       " 'Belge': 10410,\n",
       " 'leriyle': 3537,\n",
       " 'Dolaşık': 16940,\n",
       " 'Tatlan': 29125,\n",
       " 'Buldozer': 9018,\n",
       " 'baryum': 22104,\n",
       " 'tınaz': 13032,\n",
       " 'Plankton': 21007,\n",
       " 'Çekmece': 15447,\n",
       " 'kişinin': 4818,\n",
       " 'Zeybek': 8095,\n",
       " 'van': 1712,\n",
       " '成': 1002,\n",
       " 'rahatsızlan': 14413,\n",
       " 'kuruş': 17717,\n",
       " 'Dizey': 27226,\n",
       " 'bakraç': 24029,\n",
       " 'İmparator': 2387,\n",
       " 'Amortisör': 28447,\n",
       " 'ύ': 367,\n",
       " 'Otur': 15087,\n",
       " 'organ': 2991,\n",
       " 'radyan': 16452,\n",
       " 'Sch': 2715,\n",
       " 'pişman': 10769,\n",
       " 'Washington': 5864,\n",
       " '（': 1200,\n",
       " 'ortaklık': 11644,\n",
       " '春': 1017,\n",
       " 'ortaçağ': 19321,\n",
       " 'Çekirdek': 22057,\n",
       " 'şövale': 28216,\n",
       " 'boyana': 22620,\n",
       " 'zafer': 6890,\n",
       " 'kitre': 12927,\n",
       " 'Birey': 7284,\n",
       " 'tören': 6746,\n",
       " 'Irtibat': 14872,\n",
       " 'antijen': 16075,\n",
       " 'dor': 6092,\n",
       " 'mihver': 21326,\n",
       " 'Sınav': 19026,\n",
       " 'Boynuzla': 29182,\n",
       " 'nurlan': 15598,\n",
       " 'Çamurla': 16304,\n",
       " 'Güzelleme': 7808,\n",
       " 'Doğan': 6748,\n",
       " 'Pirit': 11845,\n",
       " 'Yasadışı': 20118,\n",
       " '本': 1023,\n",
       " 'miting': 29902,\n",
       " 'Umutlan': 16164,\n",
       " 'Mezarlığı': 6628,\n",
       " 'Kaybet': 12627,\n",
       " 'dişçi': 7736,\n",
       " 'merak': 17227,\n",
       " 'bölü': 23368,\n",
       " 'Buda': 21924,\n",
       " 'Çiftetelli': 20024,\n",
       " 'moloz': 28913,\n",
       " 'Balçık': 21107,\n",
       " 'omur': 23728,\n",
       " 'Dinamo': 11794,\n",
       " 'Mensup': 13835,\n",
       " 'armonik': 12029,\n",
       " 'sigortala': 24624,\n",
       " 'gelmiştir': 5427,\n",
       " 'Mayonez': 22042,\n",
       " 'akademisyen': 6589,\n",
       " 'Sitem': 23968,\n",
       " 'doğ': 1397,\n",
       " 'saldır': 2487,\n",
       " 'silahlan': 28544,\n",
       " 'maskot': 7657,\n",
       " 'fotomodel': 12288,\n",
       " 'radyatör': 23592,\n",
       " 'teleskopik': 7373,\n",
       " 'karavan': 14649,\n",
       " 'Sülük': 10589,\n",
       " 'Uyanık': 8890,\n",
       " 'mekanizasyon': 17084,\n",
       " 'kist': 10552,\n",
       " 'kolektif': 8840,\n",
       " 'duba': 23978,\n",
       " 'hazne': 15106,\n",
       " 'misket': 26408,\n",
       " 'yansıtıcı': 21989,\n",
       " 'Misafirhane': 9790,\n",
       " 'ıktan': 6185,\n",
       " 'uyar': 3156,\n",
       " 'Haylaz': 19735,\n",
       " 'Nitelen': 18168,\n",
       " 'kramp': 27298,\n",
       " 'ürün': 3516,\n",
       " 'Özgül': 14698,\n",
       " 'Kabul': 7998,\n",
       " 'Zağ': 23832,\n",
       " 'müdafi': 26557,\n",
       " 'Sportmen': 22740,\n",
       " 'Nutuk': 9293,\n",
       " 'Komite': 20497,\n",
       " 'aydınlan': 15392,\n",
       " 'Paylaşım': 25259,\n",
       " 'Amerikan': 2741,\n",
       " 'kıyı': 5353,\n",
       " 'bozayı': 7271,\n",
       " 'Muhalefet': 9686,\n",
       " 'Idealizm': 18484,\n",
       " 'Masumiyet': 27978,\n",
       " 'silisyum': 29841,\n",
       " 'haczet': 22344,\n",
       " 'palazla': 23033,\n",
       " 'istiklal': 20680,\n",
       " 'genotip': 29281,\n",
       " 'magma': 24922,\n",
       " 'reprodüksiyon': 10672,\n",
       " 'sahn': 4345,\n",
       " 'Güz': 23453,\n",
       " 'Indikatör': 18004,\n",
       " 'asabi': 23106,\n",
       " 'eğitsel': 26008,\n",
       " 'çıvgın': 15717,\n",
       " 'Mukallit': 18093,\n",
       " 'Tababet': 19214,\n",
       " 'Kastor': 8000,\n",
       " 'Kafadar': 16050,\n",
       " 'Yükümlü': 25644,\n",
       " 'Lond': 3280,\n",
       " 'Gardırop': 8550,\n",
       " 'Öç': 17788,\n",
       " 'haberdar': 24887,\n",
       " 'Tunç': 25679,\n",
       " 'ole': 5182,\n",
       " 'övünç': 18677,\n",
       " 'Sadır': 27147,\n",
       " 'Inci': 18720,\n",
       " 'Kuşdili': 24268,\n",
       " 'meyva': 15659,\n",
       " 'jakoben': 29383,\n",
       " 'Ravent': 23865,\n",
       " 'Yaba': 20257,\n",
       " 'Boğuk': 22233,\n",
       " 'haybe': 15844,\n",
       " 'Ruhi': 29645,\n",
       " 'Zar': 7267,\n",
       " 'Şereflen': 20627,\n",
       " 'hak': 1791,\n",
       " 'büyük': 1636,\n",
       " 'Kuyruk': 28591,\n",
       " 'yal': 1812,\n",
       " 'lunapark': 18344,\n",
       " 'ris': 2445,\n",
       " 'Boa': 24984,\n",
       " 'Triton': 14527,\n",
       " 'kucak': 8887,\n",
       " 'butik': 11679,\n",
       " 'balkon': 18639,\n",
       " 'bukalemun': 13016,\n",
       " 'damat': 25453,\n",
       " 'Övünç': 8962,\n",
       " 'sönüm': 25801,\n",
       " 'olanca': 16527,\n",
       " 'Karşılık': 10805,\n",
       " 'Tipoloji': 26628,\n",
       " 'Aşık': 13035,\n",
       " 'fars': 12188,\n",
       " 'Prim': 22722,\n",
       " 'Çimento': 23231,\n",
       " 'Solucan': 20463,\n",
       " 'öner': 4234,\n",
       " 'Temsili': 14251,\n",
       " 'Garanti': 28317,\n",
       " 'Mahsus': 15572,\n",
       " 'şahika': 18401,\n",
       " 'İngiltere': 2643,\n",
       " 'ы': 429,\n",
       " 'kavur': 26620,\n",
       " 'paranoya': 18648,\n",
       " 'efor': 26147,\n",
       " 'Nida': 14226,\n",
       " 'teknoloji': 26180,\n",
       " 'David': 3814,\n",
       " 'ὴ': 741,\n",
       " 'Torna': 12372,\n",
       " 'aygır': 20704,\n",
       " 'adamı': 5720,\n",
       " 'Manda': 20045,\n",
       " 'ses': 2163,\n",
       " 'Heyecan': 18937,\n",
       " 'Torpille': 26185,\n",
       " 'laza': 12635,\n",
       " 'lov': 3825,\n",
       " 'Jet': 25596,\n",
       " 'aruz': 16231,\n",
       " 'Ikrar': 19754,\n",
       " 'üfusu': 2676,\n",
       " 'Mağduriyet': 10245,\n",
       " 'tabu': 20518,\n",
       " 'pulla': 28498,\n",
       " 'derişik': 19590,\n",
       " 'Sadist': 18808,\n",
       " 'olumlu': 14086,\n",
       " 'tapu': 27982,\n",
       " 'kadim': 11926,\n",
       " 'süslü': 17448,\n",
       " 'Kase': 18469,\n",
       " 'Ilköğrenim': 9060,\n",
       " 'Patolog': 21833,\n",
       " 'Parke': 27334,\n",
       " 'Mambo': 21080,\n",
       " 'hey': 3829,\n",
       " 'tıkları': 6424,\n",
       " 'Girift': 22259,\n",
       " 'tutun': 9475,\n",
       " 'Fütürist': 26120,\n",
       " 'Presleme': 18272,\n",
       " 'halet': 18430,\n",
       " '2010': 1955,\n",
       " 'olog': 2857,\n",
       " 'Peşrev': 16566,\n",
       " 'Oh': 7898,\n",
       " 'Havla': 11623,\n",
       " 'Açelya': 15086,\n",
       " 'tanker': 28224,\n",
       " 'arkadaş': 3180,\n",
       " 'Primat': 8673,\n",
       " 'Leğen': 19506,\n",
       " 'maktul': 7927,\n",
       " 'gak': 9059,\n",
       " 'Kefe': 18379,\n",
       " 'Teveccüh': 11166,\n",
       " 'Zavallı': 16839,\n",
       " 'cidar': 23001,\n",
       " 'tanen': 20427,\n",
       " 'Akıl': 23503,\n",
       " 'Şıpka': 26546,\n",
       " 'Civan': 26997,\n",
       " 'vakum': 16069,\n",
       " 'hisset': 21455,\n",
       " 'sürdür': 3377,\n",
       " 'Lehimle': 21790,\n",
       " 'motive': 12723,\n",
       " 'tipografi': 26572,\n",
       " 'Kağıt': 28961,\n",
       " 'Karavana': 22669,\n",
       " 'Azık': 12583,\n",
       " 'kuram': 17918,\n",
       " 'başta': 5970,\n",
       " 'kuaför': 12908,\n",
       " 'Jüri': 14963,\n",
       " 'statüko': 15358,\n",
       " 'mikado': 13724,\n",
       " 'Valf': 24556,\n",
       " 'Elektrodinamik': 7276,\n",
       " 'Anaerkil': 13573,\n",
       " 'he': 1378,\n",
       " 'mayan': 4486,\n",
       " 'Beşparmak': 17876,\n",
       " 'Davar': 19016,\n",
       " 'Alet': 7318,\n",
       " 'sen': 1828,\n",
       " 'yayımlanan': 5147,\n",
       " 'efsun': 12702,\n",
       " 'Koçu': 11105,\n",
       " 'biber': 20100,\n",
       " 'Reçete': 15188,\n",
       " 'çile': 14172,\n",
       " 'Omurgasızlar': 17003,\n",
       " 'Mayın': 22126,\n",
       " 'Toprakla': 21558,\n",
       " 'kurgula': 20876,\n",
       " 'orkestra': 7229,\n",
       " 'Raks': 19226,\n",
       " 'köpük': 9792,\n",
       " 'Tramvay': 20784,\n",
       " 'Vokal': 13780,\n",
       " 'egemen': 6041,\n",
       " 'Kaburga': 11822,\n",
       " 'ıl': 1237,\n",
       " 'Keyif': 19917,\n",
       " 'Ataerkil': 17306,\n",
       " 'Limuzin': 16491,\n",
       " 'müftü': 19807,\n",
       " 'gitti': 5263,\n",
       " 'Tuğgeneral': 21207,\n",
       " 'ئ': 540,\n",
       " 'Paradigma': 10685,\n",
       " 'birahane': 22562,\n",
       " 'hangar': 12607,\n",
       " 'yoktur': 5154,\n",
       " 'Kılıfla': 22560,\n",
       " 'nargile': 11831,\n",
       " 'ayırt': 28045,\n",
       " 'rami': 20830,\n",
       " 'zahire': 8703,\n",
       " 'karabuğday': 21593,\n",
       " 'Uskumru': 24613,\n",
       " 'Koordine': 8442,\n",
       " '43': 4890,\n",
       " 'Ofis': 19445,\n",
       " 'Seyyah': 21698,\n",
       " 'Sağdıç': 17241,\n",
       " 'Entegrasyon': 18992,\n",
       " 'Gerçekleş': 18757,\n",
       " 'koordinasyon': 15093,\n",
       " 'talak': 25680,\n",
       " 'demirbaş': 22313,\n",
       " 'Torba': 28388,\n",
       " 'takdis': 28737,\n",
       " 'magnezyum': 8036,\n",
       " 'Bukalemun': 11422,\n",
       " 'Volan': 25859,\n",
       " 'Galyum': 22338,\n",
       " 'hacim': 18542,\n",
       " 'Enter': 5991,\n",
       " 'yele': 27039,\n",
       " '1999': 2682,\n",
       " 'Koy': 24172,\n",
       " 'okaliptüs': 11154,\n",
       " 'zülal': 26697,\n",
       " 'Sorgula': 25098,\n",
       " 'Sağol': 10047,\n",
       " 'Ehliyet': 26143,\n",
       " 'vatanperver': 8462,\n",
       " 'Alan': 4570,\n",
       " 'Lime': 7208,\n",
       " 'Evre': 17765,\n",
       " 'Adana': 5533,\n",
       " 'ia': 1704,\n",
       " 'bangır': 11365,\n",
       " 'pegmatit': 11206,\n",
       " 'nesnel': 18503,\n",
       " 'Ferman': 11394,\n",
       " 'gizli': 5601,\n",
       " 'Mevlit': 20376,\n",
       " 'raj': 6558,\n",
       " 'tırman': 8994,\n",
       " 'Magmatik': 10062,\n",
       " 'nazır': 26533,\n",
       " 'eh': 1419,\n",
       " 'Antisemitizm': 11910,\n",
       " 'hamurla': 22768,\n",
       " 'gezegen': 5468,\n",
       " 'Bursa': 4974,\n",
       " 'yazla': 14852,\n",
       " '91': 6621,\n",
       " 'Tasma': 10538,\n",
       " 'müsaade': 29493,\n",
       " 'Karab': 5440,\n",
       " 'deri': 4465,\n",
       " 'Rical': 7746,\n",
       " 'tekerle': 12348,\n",
       " 'Dilinim': 23410,\n",
       " 'Fakih': 27193,\n",
       " '\\ufeff': 1199,\n",
       " 'Dolaş': 13754,\n",
       " 'ametal': 8068,\n",
       " 'Katabolizma': 9935,\n",
       " 'Epilepsi': 7520,\n",
       " 'Gazla': 19490,\n",
       " 'dilek': 11446,\n",
       " 'güneyli': 7095,\n",
       " 'dürt': 21281,\n",
       " '97': 3197,\n",
       " 'Oflaz': 29115,\n",
       " 'rahip': 29225,\n",
       " 'sersemle': 7713,\n",
       " 'Müstakim': 22545,\n",
       " 'Gürcistan': 4647,\n",
       " 'Düşür': 19450,\n",
       " 'ortaöğretim': 7353,\n",
       " 'uyarım': 23161,\n",
       " 'Büfe': 26564,\n",
       " 'kızılçam': 15415,\n",
       " 'Hac': 20910,\n",
       " 'Bergamot': 15128,\n",
       " 'şaphane': 29681,\n",
       " 'Festivali': 4371,\n",
       " 'Bıçakla': 22116,\n",
       " 'kullan': 1471,\n",
       " 'ült': 2873,\n",
       " '%;': 5936,\n",
       " 'örümcek': 5747,\n",
       " 'Mülkiye': 21592,\n",
       " 'elbette': 10817,\n",
       " 'izafiyet': 12233,\n",
       " 'Barak': 7109,\n",
       " 'Düşes': 15141,\n",
       " 'kucakla': 18393,\n",
       " 'ayva': 11161,\n",
       " 'nefes': 9483,\n",
       " 'dep': 5713,\n",
       " 'Vergile': 25131,\n",
       " 'elipsoit': 18906,\n",
       " 'olmasına': 4572,\n",
       " 'Bedii': 7331,\n",
       " 'gecelik': 14317,\n",
       " 'Uygar': 9912,\n",
       " 'Farı': 10389,\n",
       " 'Savan': 9860,\n",
       " 'enkaz': 12325,\n",
       " 'yayınladı': 5363,\n",
       " '්': 629,\n",
       " 'sağanak': 11050,\n",
       " 'Gerdan': 16804,\n",
       " 'analjezik': 24195,\n",
       " 'Bıçakçı': 23671,\n",
       " 'defa': 4879,\n",
       " 'ira': 3942,\n",
       " 'Feda': 29574,\n",
       " 'Budala': 16435,\n",
       " 'şefaat': 29387,\n",
       " 'güvensizlik': 11210,\n",
       " '別': 938,\n",
       " 'Çiftleş': 14768,\n",
       " 'Çökük': 9870,\n",
       " 'Karasinek': 14208,\n",
       " 'ad': 1241,\n",
       " 'Desinatör': 26317,\n",
       " 'ilaç': 6438,\n",
       " 'Eyvan': 16458,\n",
       " 'Paten': 17029,\n",
       " 'Fesih': 28036,\n",
       " 'neden': 1790,\n",
       " 'histoloji': 21402,\n",
       " 'Gıcırda': 23901,\n",
       " 'Çalışkan': 13933,\n",
       " 'Kruvaziyer': 29337,\n",
       " 'penisilin': 7451,\n",
       " 'с': 419,\n",
       " 'müş': 2083,\n",
       " 'Toka': 9915,\n",
       " 'karışık': 15491,\n",
       " 'Maruf': 26339,\n",
       " 'Ortodoks': 18182,\n",
       " 'Araştır': 4386,\n",
       " 'zorunluk': 29856,\n",
       " 'yaran': 28154,\n",
       " 'Sena': 25508,\n",
       " 'Diktatör': 29347,\n",
       " 'alerji': 28132,\n",
       " 'style': 1669,\n",
       " 'kain': 9922,\n",
       " 'ihanet': 30078,\n",
       " 'ski': 4274,\n",
       " 'Deklare': 19975,\n",
       " 'Abart': 27566,\n",
       " 'liler': 5339,\n",
       " 'zırh': 7084,\n",
       " 'karşıl': 2821,\n",
       " 'süren': 5373,\n",
       " 'Muham': 4196,\n",
       " 'Mutasavvıf': 17564,\n",
       " 'Maksimum': 11953,\n",
       " 'Diye': 18015,\n",
       " 'lahmacun': 13627,\n",
       " 'anemon': 24844,\n",
       " 'akit': 10893,\n",
       " 'önlem': 15617,\n",
       " 'Çıta': 17929,\n",
       " 'petrol': 18383,\n",
       " 'kızılağaç': 12153,\n",
       " 'yulaf': 21728,\n",
       " 'Sabıka': 24692,\n",
       " 'maliye': 16143,\n",
       " 'Morina': 24539,\n",
       " 'paketle': 19489,\n",
       " 'Kilis': 4542,\n",
       " 'Yeterince': 15094,\n",
       " 'Fani': 10622,\n",
       " 'Ayart': 21293,\n",
       " 'Baget': 29343,\n",
       " 'özlem': 8285,\n",
       " 'lav': 3001,\n",
       " 'çekirge': 14049,\n",
       " 'Ezan': 17502,\n",
       " 'Yurtsever': 27599,\n",
       " 'Alafranga': 24301,\n",
       " 'Mesaj': 13111,\n",
       " 'gürgen': 8572,\n",
       " 'spektrum': 8832,\n",
       " 'alkaloit': 11800,\n",
       " 'gedik': 20686,\n",
       " 'Eskrim': 15634,\n",
       " 'işçi': 13661,\n",
       " 'çıktı': 3044,\n",
       " 'kurmay': 12650,\n",
       " 'sof': 22528,\n",
       " 'Hikaye': 26951,\n",
       " 'Küt': 4498,\n",
       " 'editör': 23263,\n",
       " 'pim': 28502,\n",
       " 'Tekbir': 7816,\n",
       " 'Gayrimeşru': 26449,\n",
       " 'tutam': 12164,\n",
       " 'paleograf': 28790,\n",
       " 'hafniyum': 17106,\n",
       " 'Arjantin': 4679,\n",
       " 'fıçıla': 14100,\n",
       " 'çivit': 10920,\n",
       " 'Tedirgin': 22129,\n",
       " 'civelek': 13099,\n",
       " 'Çenek': 18451,\n",
       " 'Muhteva': 29658,\n",
       " 'Yetimhane': 22247,\n",
       " 'staj': 26399,\n",
       " 'İsa': 6680,\n",
       " 'Düzenbaz': 29655,\n",
       " 'mengene': 21093,\n",
       " 'padişah': 14307,\n",
       " 'Haşmet': 17147,\n",
       " 'Vantilatör': 21688,\n",
       " '68': 4073,\n",
       " 'Müstakil': 17520,\n",
       " 'Çakar': 13364,\n",
       " 'Kabarcık': 11998,\n",
       " 'ikamet': 22505,\n",
       " '2000': 2168,\n",
       " 'Yumuşa': 13412,\n",
       " 'Jo': 2011,\n",
       " 'る': 850,\n",
       " 'ziyade': 14643,\n",
       " 'yükseköğrenim': 20461,\n",
       " 'Manyetizma': 21505,\n",
       " 'Paskal': 25748,\n",
       " 'Nikah': 15590,\n",
       " 'Muhterem': 28489,\n",
       " 'baldız': 18628,\n",
       " 'kut': 3047,\n",
       " 'enişte': 14940,\n",
       " 'liğe': 4905,\n",
       " 'yaptır': 6073,\n",
       " 'kepez': 8307,\n",
       " 'so': 2938,\n",
       " 'ili': 1458,\n",
       " 'Konvansiyon': 18218,\n",
       " 'Inatçı': 19838,\n",
       " 'tenha': 14787,\n",
       " 'uyaran': 25995,\n",
       " 'pinel': 19547,\n",
       " '1921': 5989,\n",
       " '™': 780,\n",
       " 'Aceleci': 13577,\n",
       " 'Anımsa': 25382,\n",
       " 'kasık': 21152,\n",
       " 'Muayene': 18343,\n",
       " 'yaklaş': 2257,\n",
       " 'etkisi': 5380,\n",
       " 'Judo': 19598,\n",
       " 'sor': 2052,\n",
       " 'Ölçek': 27455,\n",
       " 'caz': 29746,\n",
       " 'Bileşen': 28473,\n",
       " 'mıknatıs': 25934,\n",
       " 'Ekstra': 23622,\n",
       " 'Yassı': 15500,\n",
       " 'trap': 22976,\n",
       " 'farmakognozi': 7446,\n",
       " 'karkas': 21972,\n",
       " 'Tröst': 28625,\n",
       " 'Garez': 9489,\n",
       " 'kapsamında': 6600,\n",
       " 'şehrin': 4392,\n",
       " 'marka': 22315,\n",
       " 'Bet': 6859,\n",
       " 'mecazi': 24664,\n",
       " 'Iğ': 9737,\n",
       " 'acaktır': 5711,\n",
       " 'Krema': 7973,\n",
       " '٠': 577,\n",
       " 'Inkılap': 9881,\n",
       " 'sırılsıklam': 11232,\n",
       " 'nız': 3289,\n",
       " 'bilgin': 23606,\n",
       " 'rist': 2688,\n",
       " 'termik': 18956,\n",
       " 'göster': 1751,\n",
       " 'landa': 2912,\n",
       " 'ehlibeyt': 24606,\n",
       " 'Halhal': 17348,\n",
       " 'Kördüğüm': 20583,\n",
       " 'maşık': 6081,\n",
       " 'çiy': 8543,\n",
       " 'Hidra': 15172,\n",
       " 'Tertibat': 24092,\n",
       " 'üretimi': 6456,\n",
       " 'kutula': 7844,\n",
       " 'trompet': 26215,\n",
       " 'E9': 1656,\n",
       " 'Kup': 2166,\n",
       " 'Dargın': 27679,\n",
       " 'tezkire': 24739,\n",
       " 'popülasyon': 25062,\n",
       " 'Bitkisel': 24466,\n",
       " 'Had': 9546,\n",
       " 'dost': 10663,\n",
       " 'kete': 10754,\n",
       " 'dalgın': 11967,\n",
       " 'sit': 1538,\n",
       " 'yalıt': 29875,\n",
       " 'bibliyografi': 30082,\n",
       " 'Kürt': 4865,\n",
       " 'leyen': 3498,\n",
       " 'ɬ': 274,\n",
       " 'çağrışım': 7688,\n",
       " 'askeriye': 11474,\n",
       " 'Teknik': 4616,\n",
       " 'Bilişim': 14799,\n",
       " 'tanesi': 6208,\n",
       " 'mahir': 21462,\n",
       " 'Yüksek': 3517,\n",
       " 'sur': 3549,\n",
       " 'Yerleş': 15543,\n",
       " 'Kalay': 10452,\n",
       " 'Makine': 27403,\n",
       " 'çekimser': 29348,\n",
       " 'Ekseri': 13752,\n",
       " 'ısırık': 7600,\n",
       " 'Af': 2128,\n",
       " '당': 1127,\n",
       " 'kovalamaca': 14304,\n",
       " 'Tezgah': 20568,\n",
       " 'Hora': 22745,\n",
       " 'Dekatlon': 28209,\n",
       " 'şayan': 22611,\n",
       " 'yaka': 25164,\n",
       " 'dizi': 2945,\n",
       " 'Öv': 20732,\n",
       " 'destek': 2541,\n",
       " 'imiz': 6098,\n",
       " 'akyuvar': 20788,\n",
       " 'Çemberle': 22559,\n",
       " 'Bidon': 7471,\n",
       " 'apse': 17516,\n",
       " 'Yeti': 14035,\n",
       " 'lime': 9119,\n",
       " 'Raf': 25793,\n",
       " 'Hitap': 28520,\n",
       " 'şarlatanlık': 25033,\n",
       " 'namzet': 11660,\n",
       " '79': 5883,\n",
       " 'Yeke': 16871,\n",
       " 'Sütun': 26066,\n",
       " 'dosdoğru': 24682,\n",
       " 'msı': 19376,\n",
       " 'Şakayık': 30147,\n",
       " 'tehlike': 29465,\n",
       " 'madalyon': 9448,\n",
       " 'idadi': 16605,\n",
       " 'müttefik': 11570,\n",
       " 'Tahriş': 19934,\n",
       " 'yüzbaşı': 21877,\n",
       " 'ancak': 1977,\n",
       " 'ur': 1239,\n",
       " 'etiketle': 10667,\n",
       " 'Kast': 21161,\n",
       " 'çekmen': 28179,\n",
       " 'kloroplast': 8530,\n",
       " 'Mezalim': 15332,\n",
       " 'Taban': 14907,\n",
       " 'Ödem': 19186,\n",
       " 'Eklemle': 10425,\n",
       " 'raf': 1634,\n",
       " 'siyonu': 3995,\n",
       " 'Ağla': 15532,\n",
       " 'kontrbas': 10303,\n",
       " 'Bekri': 28589,\n",
       " 'santrifüj': 10616,\n",
       " 'faiz': 14275,\n",
       " 'Uyan': 28504,\n",
       " 'konum': 4217,\n",
       " 'Polonyum': 27704,\n",
       " 'Şecere': 12486,\n",
       " 'ekseriyet': 19820,\n",
       " '1996': 2830,\n",
       " 'mililitre': 14335,\n",
       " 'Minnet': 15526,\n",
       " 'Kötülük': 29674,\n",
       " 'bahir': 11348,\n",
       " 'Christ': 5338,\n",
       " 'edebiyat': 5283,\n",
       " 'kırkayak': 10095,\n",
       " 'içindeki': 5738,\n",
       " 'kronometre': 25013,\n",
       " 'Sadrazam': 18175,\n",
       " 'inayet': 30055,\n",
       " 'nohut': 15961,\n",
       " 'eğlen': 16400,\n",
       " 'astar': 7255,\n",
       " 'bürokrasi': 8952,\n",
       " 'Adaylık': 5539,\n",
       " 'Toplardamar': 9813,\n",
       " 'tünek': 16044,\n",
       " 'efendi': 10701,\n",
       " 'stilistik': 12492,\n",
       " 'Kırbaçla': 25016,\n",
       " 'Anayasal': 7372,\n",
       " 'öğreti': 24599,\n",
       " 'doktor': 4510,\n",
       " 'Tepe': 28183,\n",
       " 'oksidasyon': 9468,\n",
       " 'Elverişli': 25663,\n",
       " 'muavenet': 15041,\n",
       " 'Cıvatala': 16984,\n",
       " ...}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alibayram/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import GemmaTokenizerFast\n",
    "\n",
    "gemma2_tokenizer = GemmaTokenizerFast.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "gemma2_tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"aa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = gemma2_tokenizer(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gemma2_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgemma2_model\u001b[49m\u001b[38;5;241m.\u001b[39mgeneration_config\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gemma2_model' is not defined"
     ]
    }
   ],
   "source": [
    "gemma2_model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   2, 6499]]), 'attention_mask': tensor([[1, 1]])}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The current model class (Gemma2Model) is not compatible with `.generate()`, as it doesn't have a language model head. Classes that support generation often end in one of these names: ['ForCausalLM', 'ForConditionalGeneration', 'ForSpeechSeq2Seq', 'ForVision2Seq'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mgemma_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/generation/utils.py:1802\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \n\u001b[1;32m   1720\u001b[0m \u001b[38;5;124;03mGenerates sequences of token ids for models with a language modeling head.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;124;03m            - [`~generation.GenerateBeamEncoderDecoderOutput`]\u001b[39;00m\n\u001b[1;32m   1800\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1801\u001b[0m \u001b[38;5;66;03m# 1. Handle `generation_config` and kwargs that might update it, and validate the `.generate()` call\u001b[39;00m\n\u001b[0;32m-> 1802\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1803\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# Pull this out first, we only use it for stopping criteria\u001b[39;00m\n\u001b[1;32m   1804\u001b[0m generation_config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_generation_config(generation_config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/generation/utils.py:1125\u001b[0m, in \u001b[0;36mGenerationMixin._validate_model_class\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcan_generate():\n\u001b[1;32m   1119\u001b[0m     terminations_with_generation_support \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForCausalLM\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForConditionalGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForSpeechSeq2Seq\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForVision2Seq\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1124\u001b[0m     ]\n\u001b[0;32m-> 1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current model class (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is not compatible with `.generate()`, as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1127\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a language model head. Classes that support generation often end in one of these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1128\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mterminations_with_generation_support\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1129\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: The current model class (Gemma2Model) is not compatible with `.generate()`, as it doesn't have a language model head. Classes that support generation often end in one of these names: ['ForCausalLM', 'ForConditionalGeneration', 'ForSpeechSeq2Seq', 'ForVision2Seq']."
     ]
    }
   ],
   "source": [
    "outputs = gemma_model.generate(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos>aa<2mass><2mass><eos>'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma2_tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alibayram/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%python` not found (But cell magic `%%python` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "%python -m pip install --upgrade pip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
